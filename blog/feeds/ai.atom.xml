<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Blog - ai</title><link href="https://lellep.xyz/blog/" rel="alternate"></link><link href="https://lellep.xyz/blog/feeds/ai.atom.xml" rel="self"></link><id>https://lellep.xyz/blog/</id><updated>2025-04-26T00:00:00+02:00</updated><subtitle>by Martin Lellep</subtitle><entry><title>An AI App for my¬†Mom</title><link href="https://lellep.xyz/blog/ai-app-for-my-mom.html" rel="alternate"></link><published>2025-04-26T00:00:00+02:00</published><updated>2025-04-26T00:00:00+02:00</updated><author><name>Martin Lellep</name></author><id>tag:lellep.xyz,2025-04-26:/blog/ai-app-for-my-mom.html</id><summary type="html">&lt;p class="first last"&gt;I built an &lt;span class="caps"&gt;AI&lt;/span&gt; app to help my mom transcribe audio embedded in PowerPoint&amp;nbsp;slides.&lt;/p&gt;
</summary><content type="html">&lt;p&gt;&lt;a class="reference external" href="https://lellep.xyz/projects/pptx_audio_transcriber/?utm_campaign=fromBlogArticle1"&gt;üîó Link to &lt;span class="caps"&gt;AI&lt;/span&gt; app for my&amp;nbsp;mom&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="mailto:blog.ma.lel&amp;#64;gmail.com?subject=Feedback%20for%20An%20AI%20App%20for%20my%20Mom&amp;amp;body=Drop%20your%20feedback%20here.%20Thanks%20a%20lot!%20%3A-)"&gt;üí¨ Send me feedback about this&amp;nbsp;article&lt;/a&gt;&lt;/p&gt;
&lt;div class="contents topic" id="table-of-contents"&gt;
&lt;p class="topic-title"&gt;&lt;a class="reference internal" href="#top"&gt;Table of&amp;nbsp;Contents:&lt;/a&gt;&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#the-problem-transcribing-audio-in-powerpoint" id="toc-entry-1"&gt;The Problem: Transcribing Audio in&amp;nbsp;PowerPoint&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#the-task-use-ai-to-help-my-mom" id="toc-entry-2"&gt;The Task: Use &lt;span class="caps"&gt;AI&lt;/span&gt; to Help my&amp;nbsp;Mom&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#v1-a-quick-python-app-using-reflex-whisper" id="toc-entry-3"&gt;V1: A Quick Python App Using Reflex +&amp;nbsp;Whisper&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#v2-going-fully-client-side-with-vanilla-js" id="toc-entry-4"&gt;V2: Going Fully Client-Side with Vanilla &lt;span class="caps"&gt;JS&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#results-and-reflection" id="toc-entry-5"&gt;Results and&amp;nbsp;Reflection&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;p&gt;&lt;em&gt;My mom occasionally needs to transcribe the audio embedded in PowerPoint slides for her job. Each slide often contains a voiceover, and the manual transcription process used to take her weeks. I built a small tool ‚Äî first in Python with Reflex, then later as a pure client-side JavaScript app ‚Äî that automates the entire process using OpenAI‚Äôs Whisper &lt;span class="caps"&gt;API&lt;/span&gt;. In this post, I‚Äôll break down the problem, my approach, the two iterations of the system, and a few lessons&amp;nbsp;learned.&lt;/em&gt;&lt;/p&gt;
&lt;div class="section" id="the-problem-transcribing-audio-in-powerpoint"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#table-of-contents"&gt;The Problem: Transcribing Audio in&amp;nbsp;PowerPoint&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;My mom often works with PowerPoint presentations that have embedded audio ‚Äî one clip per slide (see the figure below). The goal: transcribe all the audio into editable&amp;nbsp;text.&lt;/p&gt;
&lt;div class="figure"&gt;
&lt;img alt="" src="https://lellep.xyz/blog/images/ai_app_for_my_mom/slide_explanation.png" style="width: 80%;" /&gt;
&lt;p class="caption"&gt;Schematic diagram showing two PowerPoint slide decks, one with and one without&amp;nbsp;audio.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;PowerPoint doesn‚Äôt expose this audio cleanly, and there‚Äôs no built-in way to transcribe it. The manual workflow involved opening each slide, playing the audio, and typing it out by hand. For decks with 30‚Äì40 slides, this could easily take a week or&amp;nbsp;more.&lt;/p&gt;
&lt;p&gt;The real bottleneck was that each clip required multiple listen‚Äìtype‚Äìrewind passes, with no way to batch the&amp;nbsp;work.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="the-task-use-ai-to-help-my-mom"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#table-of-contents"&gt;The Task: Use &lt;span class="caps"&gt;AI&lt;/span&gt; to Help my&amp;nbsp;Mom&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Watching this unfold, it was obvious that most of the effort was mechanical ‚Äî listen, type, rewind, repeat. A machine could do&amp;nbsp;that.&lt;/p&gt;
&lt;p&gt;That‚Äôs when I started thinking: &lt;em&gt;&lt;span class="caps"&gt;AI&lt;/span&gt; should be able to help here&lt;/em&gt;. Speech recognition has come a long way, and models like OpenAI‚Äôs Whisper had recently become accessible via &lt;span class="caps"&gt;API&lt;/span&gt;. The idea was simple: extract the audio from each slide, feed it into Whisper, and return clean text grouped by&amp;nbsp;slide.&lt;/p&gt;
&lt;p&gt;From a technical standpoint, the task broke down into three&amp;nbsp;parts:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;Parse the &lt;tt class="docutils literal"&gt;.pptx&lt;/tt&gt; file and extract all embedded&amp;nbsp;audio.&lt;/li&gt;
&lt;li&gt;Transcribe each audio clip using an &lt;span class="caps"&gt;AI&lt;/span&gt;&amp;nbsp;model.&lt;/li&gt;
&lt;li&gt;Present the output in a way that&amp;#8217;s easy to edit or&amp;nbsp;reuse.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This seemed very doable with off-the-shelf tools. My goal was to build the &lt;em&gt;simplest possible version&lt;/em&gt; to reduce my mom‚Äôs manual workload ‚Äî and avoid becoming her permanent tech&amp;nbsp;support.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="v1-a-quick-python-app-using-reflex-whisper"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#table-of-contents"&gt;V1: A Quick Python App Using Reflex +&amp;nbsp;Whisper&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;The first version of the app used &lt;a class="reference external" href="https://reflex.dev/"&gt;Reflex&lt;/a&gt; (formerly Pynecone), a Python framework that compiles into a React frontend. Since I was already comfortable in Python and wanted to move fast, it was a great&amp;nbsp;fit.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Tech Stack for&amp;nbsp;V1:&lt;/strong&gt;&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Frontend: Reflex (Python, compiles to&amp;nbsp;React)&lt;/li&gt;
&lt;li&gt;Backend: Dockerized FastAPI (local&amp;nbsp;only)&lt;/li&gt;
&lt;li&gt;Transcription: OpenAI Whisper &lt;span class="caps"&gt;API&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;Input: &lt;tt class="docutils literal"&gt;.pptx&lt;/tt&gt; files uploaded&amp;nbsp;manually&lt;/li&gt;
&lt;li&gt;Output: plain-text transcripts grouped by&amp;nbsp;slide&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;How it&amp;nbsp;worked:&lt;/strong&gt;&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;tt class="docutils literal"&gt;.pptx&lt;/tt&gt; files are just &lt;span class="caps"&gt;ZIP&lt;/span&gt;&amp;nbsp;archives.&lt;/li&gt;
&lt;li&gt;Audio files (typically &lt;tt class="docutils literal"&gt;.m4a&lt;/tt&gt; or &lt;tt class="docutils literal"&gt;.mp3&lt;/tt&gt;) are extracted from the &lt;tt class="docutils literal"&gt;ppt/media&lt;/tt&gt; folder.&lt;/li&gt;
&lt;li&gt;Each audio file is passed to Whisper for&amp;nbsp;transcription.&lt;/li&gt;
&lt;li&gt;Transcripts are grouped by slide and returned as a downloadable &lt;tt class="docutils literal"&gt;.txt&lt;/tt&gt; file.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="figure"&gt;
&lt;img alt="" src="https://lellep.xyz/blog/images/ai_app_for_my_mom/system_design_v1.png" style="width: 100%;" /&gt;
&lt;p class="caption"&gt;System design diagram for version 1. The user uploads a PowerPoint deck through the frontend; the backend extracts audio, sends it to OpenAI Whisper for transcription, and returns the text to the&amp;nbsp;frontend.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;This worked well as a proof-of-concept ‚Äî but the workflow was clunky. My mom had to send me the file, I ran the app locally in Docker, then sent her the results. Definitely not&amp;nbsp;ideal.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="v2-going-fully-client-side-with-vanilla-js"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#table-of-contents"&gt;V2: Going Fully Client-Side with Vanilla &lt;span class="caps"&gt;JS&lt;/span&gt;&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;For the second version, I removed the backend&amp;nbsp;completely.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Why?&lt;/strong&gt;&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;I didn‚Äôt want to host or maintain a&amp;nbsp;server.&lt;/li&gt;
&lt;li&gt;The Whisper &lt;span class="caps"&gt;API&lt;/span&gt; could be called directly from the&amp;nbsp;browser.&lt;/li&gt;
&lt;li&gt;The only &amp;#8220;secret&amp;#8221; needed was the OpenAI &lt;span class="caps"&gt;API&lt;/span&gt; key, which I could hand over manually. (My mom doesn&amp;#8217;t know what an &lt;span class="caps"&gt;API&lt;/span&gt; key is, but she&amp;#8217;s fine pasting it in if I give it to&amp;nbsp;her.)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Tech Stack for&amp;nbsp;V2:&lt;/strong&gt;&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Pure &lt;span class="caps"&gt;HTML&lt;/span&gt; + JavaScript (no&amp;nbsp;frameworks)&lt;/li&gt;
&lt;li&gt;Deployed as a static&amp;nbsp;site&lt;/li&gt;
&lt;li&gt;Transcription via Whisper, called from the&amp;nbsp;frontend&lt;/li&gt;
&lt;li&gt;User supplies their own &lt;span class="caps"&gt;API&lt;/span&gt;&amp;nbsp;key&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="figure"&gt;
&lt;img alt="" src="https://lellep.xyz/blog/images/ai_app_for_my_mom/system_design_v2.png" style="width: 100%;" /&gt;
&lt;p class="caption"&gt;System design diagram for version 2. Everything happens client-side: the user uploads a PowerPoint deck, the browser parses and extracts audio, sends it to Whisper, and displays the results ‚Äî no server&amp;nbsp;required.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Here‚Äôs what the app looks like (or &lt;a class="reference external" href="https://lellep.xyz/projects/pptx_audio_transcriber/?utm_campaign=fromBlogArticle2"&gt;try it here&lt;/a&gt;):&lt;/p&gt;
&lt;div class="figure"&gt;
&lt;img alt="" src="https://lellep.xyz/blog/images/ai_app_for_my_mom/app_screenshot.png" style="width: 100%;" /&gt;
&lt;p class="caption"&gt;Screenshot of the deployed app. Upload your PowerPoint deck, paste your OpenAI &lt;span class="caps"&gt;API&lt;/span&gt; key, and start transcribing ‚Äî all in a few&amp;nbsp;clicks.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;In this version, my mom uploads a &lt;tt class="docutils literal"&gt;.pptx&lt;/tt&gt; file, the browser (using &lt;tt class="docutils literal"&gt;JSZip&lt;/tt&gt;) unpacks it, extracts audio clips, and sends them to Whisper one by one. Transcriptions appear inline and are available for&amp;nbsp;download.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Security note:&lt;/strong&gt;
The &lt;span class="caps"&gt;API&lt;/span&gt; key is never stored or logged. Everything happens in-browser.
It‚Äôs not perfect &lt;span class="caps"&gt;UX&lt;/span&gt;, but for a one-user internal tool, it‚Äôs good&amp;nbsp;enough.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="results-and-reflection"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#table-of-contents"&gt;Results and&amp;nbsp;Reflection&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Today, my mom completes what used to take &lt;strong&gt;a week&lt;/strong&gt; in &lt;strong&gt;a couple of hours&lt;/strong&gt;. The app is reliable, simple, and basically&amp;nbsp;maintenance-free.&lt;/p&gt;
&lt;p&gt;A few quick lessons from the&amp;nbsp;project:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;tt class="docutils literal"&gt;.pptx&lt;/tt&gt; files are just ZIPs with predictable structure ‚Äî very&amp;nbsp;convenient.&lt;/li&gt;
&lt;li&gt;Client-side-only apps are underrated for small tools like&amp;nbsp;this.&lt;/li&gt;
&lt;li&gt;Whisper is impressively robust, even with low-quality or mumbled&amp;nbsp;audio.&lt;/li&gt;
&lt;li&gt;Reflex is a fun and productive way to build full-stack apps in&amp;nbsp;Python.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This was a super satisfying project: practical, personal, and technically interesting without ballooning in&amp;nbsp;scope.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Next steps:&lt;/strong&gt; None. Mission accomplished.&amp;nbsp;ü´∂&lt;/p&gt;
&lt;hr class="docutils" /&gt;
&lt;p&gt;üîó &lt;a class="reference external" href="https://lellep.xyz/projects/pptx_audio_transcriber/?utm_campaign=fromBlogArticle3"&gt;Try the app&amp;nbsp;yourself&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;üí¨ &lt;a class="reference external" href="mailto:blog.ma.lel&amp;#64;gmail.com?subject=Feedback%20for%20An%20AI%20App%20for%20my%20Mom&amp;amp;body=Drop%20your%20feedback%20here.%20Thanks%20a%20lot!%20%3A-)"&gt;Feedback? I&amp;#8217;d love to hear&amp;nbsp;it&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Big thanks to &lt;a class="reference external" href="https://mgmmmmm.com/?ref=lellep.xyz"&gt;Makers Gonna Make Edinburgh&lt;/a&gt; and Peter for organizing the Saturday hackathons where I built this!&amp;nbsp;‚ù§Ô∏è&lt;/p&gt;
&lt;/div&gt;
</content><category term="ai"></category><category term="ai"></category><category term="data"></category><category term="useful"></category><category term="gen-ai"></category></entry></feed>