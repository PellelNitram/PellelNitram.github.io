<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Blog</title><link href="http://lellep.xyz/blog/" rel="alternate"></link><link href="http://lellep.xyz/blog/feeds/all.atom.xml" rel="self"></link><id>http://lellep.xyz/blog/</id><updated>2020-05-10T00:00:00+02:00</updated><entry><title>How to use 3D scanning for CADÂ modeling</title><link href="http://lellep.xyz/blog/how-to-use-3d-scanning-for-cad-modeling.html" rel="alternate"></link><published>2020-05-10T00:00:00+02:00</published><updated>2020-05-10T00:00:00+02:00</updated><author><name>Martin Lellep</name></author><id>tag:lellep.xyz,2020-05-10:/blog/how-to-use-3d-scanning-for-cad-modeling.html</id><summary type="html">&lt;p class="first last"&gt;I show how to use 3D scanning for &lt;span class="caps"&gt;CAD&lt;/span&gt; modeling and how I built a custom &lt;span class="caps"&gt;PC&lt;/span&gt; mouse box with the method that I present here.
Neither do you need a &lt;span class="caps"&gt;GPU&lt;/span&gt; nor a powerful &lt;span class="caps"&gt;PC&lt;/span&gt; to follow along this tutorial. Also, the 3D scanning software is for&amp;nbsp;free.&lt;/p&gt;
</summary><content type="html">&lt;div style="margin: 0px auto; text-align: center; border: 4px solid #d93200; border-radius: 25px; padding: 20px; width: 80%;"&gt;
    &lt;h3&gt;Teaser&amp;nbsp;trailer&lt;/h3&gt;
    &lt;iframe width="560"
            height="315"
            src="https://www.youtube.com/embed/aft_jvATzFQ"
            frameborder="0"
            allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture"
            style="border: 0; margin: 0 auto; display:block; margin-bottom: 10px; max-width: 100%"
            allowfullscreen&gt;
    &lt;/iframe&gt;
&lt;/div&gt;
&lt;br/&gt;&lt;div class="section" id="introduction"&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;&lt;a class="reference external" href="https://en.wikipedia.org/wiki/Computer-aided_design"&gt;&lt;span class="caps"&gt;CAD&lt;/span&gt; modeling&lt;/a&gt; for building things is awesome! However, when it comes to organic shapes,
that cannot be made up of the typical squares and circles, even designers with an intermediate skill level start to&amp;nbsp;struggle.&lt;/p&gt;
&lt;p&gt;Luckily, 3D scanning can help to get 3D models of organically shaped&amp;nbsp;objects.&lt;/p&gt;
&lt;p&gt;Hence, I show you here how to utilise 3D scanning specifially for &lt;span class="caps"&gt;CAD&lt;/span&gt; modeling - and all that without the need for a &lt;span class="caps"&gt;GPU&lt;/span&gt; or a powerful &lt;span class="caps"&gt;PC&lt;/span&gt;.
As an exemplary project that also solves one of my (not so important) problems, I set myself to design a box for my (organically shaped) &lt;span class="caps"&gt;PC&lt;/span&gt; mouse.
This will help me to carry my &lt;span class="caps"&gt;PC&lt;/span&gt; mouse in my backpack more&amp;nbsp;easily.&lt;/p&gt;
&lt;p&gt;This is the agenda for this&amp;nbsp;tutorial:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#scan-preparations"&gt;Scan preparations&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#d-scanning-with-meshroom"&gt;3D scanning with Meshroom&lt;/a&gt; - an open-source photogrammetry software - using the free &lt;em&gt;Google Cloud&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#d-model-post-processing"&gt;3D model post processing&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#building-a-cad-model-around-the-3d-scan"&gt;Building a &lt;span class="caps"&gt;CAD&lt;/span&gt; model around the 3D scan&lt;/a&gt; - using &lt;em&gt;Autodesk Fusion 360&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#fabrication-and-assembly-of-the-mouse-box"&gt;Fabrication and assembly of the mouse box&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#final-product"&gt;Final product&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#summary"&gt;Summary&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#acknowledgments"&gt;Acknowledgments&lt;/a&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div class="section" id="scan-preparations"&gt;
&lt;h2&gt;Scan&amp;nbsp;preparations&lt;/h2&gt;
&lt;p&gt;Since we use photogrammetry here, the texture of the the object to be scanned should be as feature-rich and dull as possible.
If the object you plan to scan is shiny, you have to make sure to cover it in some non-shiny material: Some people use
painter&amp;#8217;s tape, special powder or simply flour if your objects permits. Furthermore, as photogrammetry identifies features
of your object, or generally speaking your whole scene, you should also make sure that the whole scene in which you take
the photos is&amp;nbsp;feature-rich.&lt;/p&gt;
&lt;p&gt;As an example, I am scanning my portable computer mouse here. Since it is shiny, I covered it in painter&amp;#8217;s tape that I
removed later on again. Additionally, I drew random symbols on that painter&amp;#8217;s tape to assist the photogrammetry software to find
distinct features that can be matched throughout the set of&amp;nbsp;pictures.&lt;/p&gt;
&lt;div&gt;
    &lt;iframe width="560"
            height="315"
            src="https://www.youtube.com/embed/G-UAAbKWsxk"
            frameborder="0"
            allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture"
            style="border: 0; margin: 0 auto; display:block; margin-bottom: 10px; max-width: 100%"
            allowfullscreen&gt;
    &lt;/iframe&gt;
&lt;/div&gt;
&lt;div class="figure"&gt;
    &lt;p class="caption"&gt;
        Video 1: All photos of the &lt;span class="caps"&gt;PC&lt;/span&gt; mouse rendered into one video. The individual picture quality has been
        reduced for this video in order to ensure a reasonably small video file size. The quality of
        the images used for the 3D scan, however, has not been reduced in any way as to get the highest scan&amp;nbsp;quality.
    &lt;/p&gt;
&lt;/div&gt;&lt;p&gt;The animation in Vid. 1 shows a video of all the images that I used for the photogrammetry procedure. As you can see in Vid. 1,
I made sure to cover the object in all possible angles, even multiple times and including close-ups of sections that might
need additional coverage. To ensure enough distinct features in the scene, I designed an A4 sheet printout with random symbols
on it: You can download it &lt;a class="reference external" href="http://lellep.xyz/blog/3D_scanning_print_out.pdf"&gt;here&lt;/a&gt; to print
the &lt;span class="caps"&gt;PDF&lt;/span&gt;&amp;nbsp;yourself.&lt;/p&gt;
&lt;p&gt;For the whole set of images I used a phone camera. I shot it outside on a cloudy day to guarantee an even lighting as photogrammetry
does not cope well with hard&amp;nbsp;shadows.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="d-scanning-with-meshroom"&gt;
&lt;h2&gt;3D scanning with&amp;nbsp;Meshroom&lt;/h2&gt;
&lt;p&gt;I use the free and amazing software &lt;em&gt;Meshroom&lt;/em&gt; (&lt;a class="reference external" href="https://alicevision.org/"&gt;https://alicevision.org/&lt;/a&gt; and &lt;a class="reference external" href="https://github.com/alicevision/meshroom"&gt;https://github.com/alicevision/meshroom&lt;/a&gt;) to perform the 3D
scan of the &lt;span class="caps"&gt;PC&lt;/span&gt; mouse, see Fig. 1 for a screenshot of Meshroom. There are great tutorials on Meshroom out there. I used, for example, this one:
&lt;a class="reference external" href="https://www.youtube.com/watch?v=k4NTf0hMjtY"&gt;https://www.youtube.com/watch?v=k4NTf0hMjtY&lt;/a&gt;.&lt;/p&gt;
&lt;div class="figure"&gt;
&lt;a class="reference external image-reference" href="http://lellep.xyz/blog/images/how_to_use_3D_scanning_for_CAD_modeling/meshroom_2019.2.0.png"&gt;&lt;img alt="" src="http://lellep.xyz/blog/images/how_to_use_3D_scanning_for_CAD_modeling/meshroom_2019.2.0.png" style="width: 500px;" /&gt;&lt;/a&gt;
&lt;p class="caption"&gt;Figure 1: Meshroom version 2019.2.0 &lt;span class="caps"&gt;GUI&lt;/span&gt; screenshot. The whole computation performed by Meshroom is defined by the &amp;#8220;Graph Editor&amp;#8221;
in the bottom and consumes pictures imported into the &amp;#8220;Images&amp;#8221; area. The final result is shown in the &amp;#8220;3D&amp;nbsp;Viewer&amp;#8221;.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Unfortunately, Meshroom requires a &lt;span class="caps"&gt;CUDA&lt;/span&gt;-capable (i.e. somewhat powerful) &lt;span class="caps"&gt;GPU&lt;/span&gt; to yield the best 3D scanning results. In the following, I show
how to run Meshroom (a) without a &lt;span class="caps"&gt;GPU&lt;/span&gt; on your computer at the cost of lower scan quality and (b) in the Google cloud on &lt;em&gt;Google Colab&lt;/em&gt; for free
at the cost of lacking a &lt;span class="caps"&gt;GUI&lt;/span&gt;. The &lt;span class="caps"&gt;GUI&lt;/span&gt; of Meshroom is well thought through and only executes underlying binary
command line tools that can also be invoked without the &lt;span class="caps"&gt;GUI&lt;/span&gt;. Most of what I am stating here is knowledge collected from the internet so that I can redirect you
to the original sources for in-depth explanations. In the following paragraphs, I expect you to have watched some tutorial on Meshroom as a
dedicated tutorial will explain the details of Meshroom much better than I could ever do&amp;nbsp;here.&lt;/p&gt;
&lt;p&gt;To run Meshroom on your computer without a &lt;span class="caps"&gt;GPU&lt;/span&gt; you should check out &lt;a class="reference external" href="https://github.com/alicevision/meshroom/wiki/Draft-Meshing"&gt;this page&lt;/a&gt;.
Also &lt;a class="reference external" href="https://github.com/alicevision/meshroom/wiki/Error:-This-program-needs-a-CUDA-Enabled-GPU"&gt;this resource&lt;/a&gt; is very good. In summary,
you remove some of the default steps from the Meshroom computation pipeline, the depth map computation to be specific, in order to remove the computation
steps that require a &lt;span class="caps"&gt;GPU&lt;/span&gt;. Depending on your computer hardware, the computation might only take a few minutes with these settings. The scan of my mouse
with this technique is shown in Fig. 2&amp;nbsp;(b).&lt;/p&gt;
&lt;p&gt;Next, we look into how to run Meshroom in the cloud on a &lt;span class="caps"&gt;GPU&lt;/span&gt; - for free. The scan of my mouse with this technique is shown in Fig. 2 (a). The procedure is as follows: You start a Google Colab instance, add a &lt;span class="caps"&gt;GPU&lt;/span&gt; runtime,
upload your images and start the Meshroom commandline binary after downloading it. Since Google Colab runs with Jupyter Notebooks, all these tasks can
be performed easily. Please check out the following notebook that I put together for you in order to start using Google Colab for 3D scanning right now:
&lt;a class="reference external" href="http://lellep.xyz/blog/3D_scanning_colab_notebook.ipynb"&gt;click&lt;/a&gt;. I based my
notebook off publicly available information, such as &lt;a class="reference external" href="https://github.com/alicevision/meshroom/wiki/Meshroom-in-Google-Colab-(cloud)"&gt;this&lt;/a&gt;. My notebook works as&amp;nbsp;follows:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;The pictures must be uploaded to the Colab instance as&amp;nbsp;&amp;#8220;my_dataset.zip&amp;#8221;.&lt;/li&gt;
&lt;li&gt;Subsequently, they are automatically unzipped, processed and finally the 3D scan is zipped to be&amp;nbsp;downloaded.&lt;/li&gt;
&lt;li&gt;My notebook is quite straightforward and well documented. Therefore, check out my comments and texts in
&lt;a class="reference external" href="http://lellep.xyz/blog/3D_scanning_colab_notebook.ipynb"&gt;the Jupyter notebook&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The 3D scan is saved by Meshroom as an &lt;span class="caps"&gt;OBJ&lt;/span&gt; file that includes both, 3D mesh information as well as the texture of the object. Figure 2 shows the results
of the 3D scan for both of the approaches, with and without &lt;span class="caps"&gt;GPU&lt;/span&gt;,&amp;nbsp;respectively.&lt;/p&gt;
&lt;div class="figure"&gt;
&lt;a class="reference external image-reference" href="http://lellep.xyz/blog/images/how_to_use_3D_scanning_for_CAD_modeling/with_vs_without_GPU.png"&gt;&lt;img alt="" src="http://lellep.xyz/blog/images/how_to_use_3D_scanning_for_CAD_modeling/with_vs_without_GPU.png" style="width: 700px;" /&gt;&lt;/a&gt;
&lt;p class="caption"&gt;Figure 2: 3D scans of my &lt;span class="caps"&gt;PC&lt;/span&gt; mouse using Meshroom. (a) Scan result using a cloud &lt;span class="caps"&gt;GPU&lt;/span&gt; to enable the full computation pipeline &lt;span class="amp"&gt;&amp;amp;&lt;/span&gt; highest quality of Meshroom.
(b) Scan result using Meshroom&amp;#8217;s &lt;span class="caps"&gt;CPU&lt;/span&gt;-only computation&amp;nbsp;steps.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;While the &lt;span class="caps"&gt;CPU&lt;/span&gt;-only computation pipeline is quicker to compute and executable on any computer, the &lt;span class="caps"&gt;GPU&lt;/span&gt;-enabled features of Meshroom do increase
the quality of the 3D scan significantly. They require a &lt;span class="caps"&gt;GPU&lt;/span&gt; and take slightly longer to compute, on the order of one hour vs on the order of minutes. Figure 2
might not be able to convey the detailed differences between the models, as it is just an image, but the &lt;span class="caps"&gt;GPU&lt;/span&gt;-enabled scan is much more detailed than the &lt;span class="caps"&gt;CPU&lt;/span&gt;-only scan: The &lt;span class="caps"&gt;CPU&lt;/span&gt;-only
model consists of 43,512 scanned faces while the &lt;span class="caps"&gt;GPU&lt;/span&gt;-enabled scan consists of 1,043,705 scanned faces. Hence, the &lt;span class="caps"&gt;GPU&lt;/span&gt;-enabled scan detected almost 20x more
faces than the &lt;span class="caps"&gt;CPU&lt;/span&gt;-only model using the exact same pictures of the &lt;span class="caps"&gt;PC&lt;/span&gt;&amp;nbsp;mouse.&lt;/p&gt;
&lt;p&gt;Hence, I recommend to always use a &lt;span class="caps"&gt;GPU&lt;/span&gt; to compute Meshroom 3D scans, in particular taking Google Colab into account as it offers free &lt;span class="caps"&gt;GPU&lt;/span&gt; compute&amp;nbsp;power.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="d-model-post-processing"&gt;
&lt;h2&gt;3D model post&amp;nbsp;processing&lt;/h2&gt;
&lt;p&gt;As photogrammetry identifies features in the images that are used in order to derive the camera perspectives, the scans might pick up parts of the
scene in which the scan is created. I used a &lt;a class="reference external" href="http://lellep.xyz/blog/3D_scanning_print_out.pdf"&gt;custom-made printout&lt;/a&gt;
to ensure that there are enough distinct features. Figure 3 (a) shows the raw
scan that comes out of Meshroom using the &lt;span class="caps"&gt;GPU&lt;/span&gt;-enabled computation pipeline executed on Google Colab and Fig. 3 (b) shows the same scan but a manually tidied up version of it. I used &lt;a class="reference external" href="https://www.blender.org/"&gt;Blender&lt;/a&gt; to remove all excess parts of the scan that are not of&amp;nbsp;relevance.&lt;/p&gt;
&lt;div class="figure"&gt;
&lt;a class="reference external image-reference" href="http://lellep.xyz/blog/images/how_to_use_3D_scanning_for_CAD_modeling/raw_scan_vs_trimmed.png"&gt;&lt;img alt="" src="http://lellep.xyz/blog/images/how_to_use_3D_scanning_for_CAD_modeling/raw_scan_vs_trimmed.png" style="width: 700px;" /&gt;&lt;/a&gt;
&lt;p class="caption"&gt;Figure 3: Cleaned 3D scan. (a) The model as computed by Meshroom. (b) Manually trimmed model to only consist of the mouse itself and no more scene&amp;nbsp;parts.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Clearly, removing the artefacts is a mandatory step here. Depending on what you want to do with your scanned model, there is another mandatory step:
Reducing the complexity of the 3D model by removing vertices. The original model as shown in Fig. 3 (a) consists of 1,043,705 faces and the trimmed
model in Fig. 3 (b) consists of only 423,706 faces without reducing the model quality at all as only the excess parts of the scan were removed.
For many applications though, even these 400k faces are too many. One such application being (consumer-grade) CADs (on a consumer-grade &lt;span class="caps"&gt;PC&lt;/span&gt;), I removed
the number of faces even further before exporting the model to a &lt;span class="caps"&gt;STL&lt;/span&gt; file. Figure 4 shows exactly&amp;nbsp;that.&lt;/p&gt;
&lt;div class="figure"&gt;
&lt;a class="reference external image-reference" href="http://lellep.xyz/blog/images/how_to_use_3D_scanning_for_CAD_modeling/stl_resolutions.png"&gt;&lt;img alt="" src="http://lellep.xyz/blog/images/how_to_use_3D_scanning_for_CAD_modeling/stl_resolutions.png" style="width: 800px;" /&gt;&lt;/a&gt;
&lt;p class="caption"&gt;Figure 4: &lt;span class="caps"&gt;STL&lt;/span&gt; models of my scanned &lt;span class="caps"&gt;PC&lt;/span&gt; mouse after reducing the number of faces. (a) The original file as shown in Fig. 3 (b) after exporting it
to &lt;span class="caps"&gt;STL&lt;/span&gt; (and, hence, without texture) with 423,706 faces. (b) &lt;span class="caps"&gt;STL&lt;/span&gt; with the number of faces reduced to 15% of the original model. (c) &lt;span class="caps"&gt;STL&lt;/span&gt; with the
number of faces reduced to 0.15% of the original model. Subfigures (b) and (c) were generated with Blender by using its
&lt;a class="reference external" href="https://docs.blender.org/manual/en/latest/modeling/modifiers/generate/decimate.html"&gt;decimate modifier&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Since I wanted to use the model to design a box around it, I needed it in &lt;span class="caps"&gt;CAD&lt;/span&gt;. Most of the &lt;span class="caps"&gt;CAD&lt;/span&gt; softwares support generic model formats like &lt;span class="caps"&gt;STL&lt;/span&gt; or &lt;span class="caps"&gt;OBJ&lt;/span&gt;
but can also transform these formats to their native data format. &lt;a class="reference external" href="https://www.youtube.com/watch?v=m5v8JO7pEAk"&gt;These&lt;/a&gt; &lt;a class="reference external" href="https://toglefritz.com/convert-a-simple-stl-into-a-body-in-fusion-360/"&gt;two&lt;/a&gt; resources show how to transform a &lt;span class="caps"&gt;STL&lt;/span&gt; to Fusion 360&amp;#8217;s native data format. This is very useful for all subsequent design steps but it comes at a high computational cost when the model is too detailed. Hence, I used the model shown in Fig. 4 (c) for being converted to a
native Fusion 360 object and to model my &lt;span class="caps"&gt;PC&lt;/span&gt; mouse box&amp;nbsp;around.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="building-a-cad-model-around-the-3d-scan"&gt;
&lt;h2&gt;Building a &lt;span class="caps"&gt;CAD&lt;/span&gt; model around the 3D&amp;nbsp;scan&lt;/h2&gt;
&lt;p&gt;I used the coarse-grained &lt;span class="caps"&gt;STL&lt;/span&gt; shown in Fig. 4 (c) to build my box around it. To do so, I imported it into Fusion 360 - the &lt;span class="caps"&gt;CAD&lt;/span&gt; I am using here - and designed a wooden
box around it. In order to take advantage of having the organic shape of my mouse in &lt;span class="caps"&gt;CAD&lt;/span&gt;, I designed custom 3D printed pieces as inserts for the wooden box to
ensure that the mouse does not move around inside the box while carrying it&amp;nbsp;on-the-go.&lt;/p&gt;
&lt;p&gt;To have the full capabilities of Fusion at hand for my mouse 3D scan, I converted it into the native Fusion data format as mentioned in the previous section. With this, I was able to use my scan with all joints and features inside Fusion. My finished &lt;span class="caps"&gt;CAD&lt;/span&gt; model is shown in Vid.&amp;nbsp;2.&lt;/p&gt;
&lt;div&gt;
    &lt;iframe width="560"
            height="315"
            src="https://www.youtube.com/embed/69HpqAb9VaY"
            frameborder="0"
            allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture"
            style="border: 0; margin: 0 auto; display:block; margin-bottom: 10px; max-width: 100%"
            allowfullscreen&gt;
    &lt;/iframe&gt;
&lt;/div&gt;
&lt;div class="figure"&gt;
    &lt;p class="caption"&gt;
        Video 2: Video of &lt;span class="caps"&gt;CAD&lt;/span&gt; model of the mouse transportation box. The 3D scanned model of my &lt;span class="caps"&gt;PC&lt;/span&gt; mouse is shown in black.
        White pieces are 3D printed plastic pieces from &lt;span class="caps"&gt;PLA&lt;/span&gt; and the wooden box is shown in wood-brown. The wooden box will
        be laser&amp;nbsp;cut.
    &lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;div class="section" id="fabrication-and-assembly-of-the-mouse-box"&gt;
&lt;h2&gt;Fabrication and assembly of the mouse&amp;nbsp;box&lt;/h2&gt;
&lt;p&gt;I made use of my private 3D printer to fabricate the organically shaped custom inner blocks for the wooden box. The wooden box itself,
I fabricated on my small hobby laser&amp;nbsp;cutter.&lt;/p&gt;
&lt;p&gt;The assembly is achieved step-wise: First, I glued the 3D printed plastic pieces to the wooden sides of the box, see Fig. 5 (a). These,
I glued together with painter&amp;#8217;s tape at first to ensure that everything fits together, see Fig. 5&amp;nbsp;(b).&lt;/p&gt;
&lt;div class="figure"&gt;
&lt;a class="reference external image-reference" href="http://lellep.xyz/blog/images/how_to_use_3D_scanning_for_CAD_modeling/assembly_step1_and_step2.png"&gt;&lt;img alt="" src="http://lellep.xyz/blog/images/how_to_use_3D_scanning_for_CAD_modeling/assembly_step1_and_step2.png" style="width: 700px;" /&gt;&lt;/a&gt;
&lt;p class="caption"&gt;Figure 5: First two steps of assembly process. (a) Plastic pieces are glued to the wooden box sides and pads are attached to
the 3D printed pieces to minimise the slag of the mouse inside the box and to avoid scratches on the mouse.
(b) The wooden box as assembled temporarily with painter&amp;#8217;s tape to ensure proper&amp;nbsp;fitting.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Only after these two steps, I glued the wooden box sides into place with wood glue to achieve a permanently assembled wooden box, see
Fig. 6 (a). Lastly, I applied clear coat to all of the wooden pieces, see Fig. 6&amp;nbsp;(b).&lt;/p&gt;
&lt;div class="figure"&gt;
&lt;a class="reference external image-reference" href="http://lellep.xyz/blog/images/how_to_use_3D_scanning_for_CAD_modeling/assembly_step3_and_step4.png"&gt;&lt;img alt="" src="http://lellep.xyz/blog/images/how_to_use_3D_scanning_for_CAD_modeling/assembly_step3_and_step4.png" style="width: 700px;" /&gt;&lt;/a&gt;
&lt;p class="caption"&gt;Figure 6: Next two steps of assembly process. (a) The permanent box glue-up with wood glue. (b) Application of liquid clear coat as
finish and to make the box more&amp;nbsp;sturdy.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;As a next step, I prepared the wooden lid for the box using the laser cutter again. Afterwards I cut and glued the leather pieces in place that
attach the lid to the main box body. There are three places that make use of the leather pieces: First, the piece that serves as hinge of the lid, second
the strap to secure the lid to the box with a velcro and lastly another leather piece is placed symmetrically to leather hinge for aesthetic
reasons. Figure 7 shows the finished leather&amp;nbsp;parts.&lt;/p&gt;
&lt;div class="figure"&gt;
&lt;a class="reference external image-reference" href="http://lellep.xyz/blog/images/how_to_use_3D_scanning_for_CAD_modeling/assembly_step5_and_step6.png"&gt;&lt;img alt="" src="http://lellep.xyz/blog/images/how_to_use_3D_scanning_for_CAD_modeling/assembly_step5_and_step6.png" style="width: 700px;" /&gt;&lt;/a&gt;
&lt;p class="caption"&gt;Figure 7: Mouse box with attached leather pieces. (a) Bottom view of the box to see all leather pieces installed. Going from left to right,
the leather pieces serve as closing mechanism of the lid that uses a velcro, hinging mechanism of the lid and aesthetic sugar to the box.
(b) Top view of the box with installed lid and leather&amp;nbsp;pieces.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;With that, the build is&amp;nbsp;finished!&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="final-product"&gt;
&lt;h2&gt;Final&amp;nbsp;product&lt;/h2&gt;
&lt;p&gt;The finished product is shown in Fig.&amp;nbsp;8.&lt;/p&gt;
&lt;div class="figure"&gt;
&lt;a class="reference external image-reference" href="http://lellep.xyz/blog/images/how_to_use_3D_scanning_for_CAD_modeling/final_product.jpg"&gt;&lt;img alt="" src="http://lellep.xyz/blog/images/how_to_use_3D_scanning_for_CAD_modeling/final_product.jpg" style="width: 500px;" /&gt;&lt;/a&gt;
&lt;p class="caption"&gt;Figure 8: My &lt;span class="caps"&gt;PC&lt;/span&gt; mouse next to its new custom&amp;nbsp;box.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Lastly, let&amp;#8217;s check out how the mouse itself likes its new box - see Vid.&amp;nbsp;3.&lt;/p&gt;
&lt;div&gt;
    &lt;iframe width="560"
            height="315"
            src="https://www.youtube.com/embed/j21O3ZNyunM"
            frameborder="0"
            allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture"
            style="border: 0; margin: 0 auto; display:block; margin-bottom: 10px; max-width: 100%"
            allowfullscreen&gt;
    &lt;/iframe&gt;
&lt;/div&gt;
&lt;div class="figure"&gt;
    &lt;p class="caption"&gt;
        Video 3: My mouse checking out its new box. It appears to me that it likes its new&amp;nbsp;accommodation.
    &lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;div class="section" id="summary"&gt;
&lt;h2&gt;Summary&lt;/h2&gt;
&lt;p&gt;In this article, I presented how the open-source 3D scanning software &lt;em&gt;Meshroom&lt;/em&gt; can be used to produce 3D scans without a &lt;span class="caps"&gt;GPU&lt;/span&gt; using
&lt;a class="reference external" href="http://lellep.xyz/blog/3D_scanning_colab_notebook.ipynb"&gt;this Jupyter notebook&lt;/a&gt;
and &lt;em&gt;Google Colab&lt;/em&gt;. Subsequently, I showed how the 3D model can be used for &lt;span class="caps"&gt;CAD&lt;/span&gt; modeling.
My demonstration use case was a transportation box for my &lt;span class="caps"&gt;PC&lt;/span&gt; mouse because it is a suitable object to be scanned and used in &lt;span class="caps"&gt;CAD&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;The steps for obtaining a 3D scan that can be used for &lt;span class="caps"&gt;CAD&lt;/span&gt; modeling are shown in Fig. 9. While I explain the &lt;span class="caps"&gt;CAD&lt;/span&gt;-specific steps with
&lt;em&gt;Autodesk Fusion 360&lt;/em&gt;, similar steps apply for most &lt;span class="caps"&gt;CAD&lt;/span&gt; softwares that are on the&amp;nbsp;market.&lt;/p&gt;
&lt;div class="figure"&gt;
&lt;a class="reference external image-reference" href="http://lellep.xyz/blog/images/how_to_use_3D_scanning_for_CAD_modeling/scanning_pipeline.png"&gt;&lt;img alt="" src="http://lellep.xyz/blog/images/how_to_use_3D_scanning_for_CAD_modeling/scanning_pipeline.png" style="width: 600px;" /&gt;&lt;/a&gt;
&lt;p class="caption"&gt;Figure 9: 3D scanning pipeline for obtaining a 3D model that can be used in &lt;span class="caps"&gt;CAD&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Particularly useful is the 3D scanning script for &lt;em&gt;Google Colab&lt;/em&gt; that I provided. With that, you are not required to own a &lt;span class="caps"&gt;GPU&lt;/span&gt;-enabled &lt;span class="caps"&gt;PC&lt;/span&gt; anymore.
Hence, the only thing you need to do to get your own 3D scan is to capture a set of pictures of the object you want to&amp;nbsp;scan.&lt;/p&gt;
&lt;p&gt;Happy&amp;nbsp;scanning!&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="acknowledgments"&gt;
&lt;h2&gt;Acknowledgments&lt;/h2&gt;
&lt;p&gt;Thanks to Jens Wienkamp for letting me run my first Meshroom experiments on his &lt;span class="caps"&gt;GPU&lt;/span&gt;!&lt;/p&gt;
&lt;/div&gt;
</content></entry><entry><title>Parking in Marburg: a quantitativeÂ study</title><link href="http://lellep.xyz/blog/parking-in-marburg.html" rel="alternate"></link><published>2020-02-26T00:00:00+01:00</published><updated>2020-02-26T00:00:00+01:00</updated><author><name>Martin Lellep</name></author><id>tag:lellep.xyz,2020-02-26:/blog/parking-in-marburg.html</id><summary type="html">&lt;p class="first last"&gt;The parking demand in Marburg is analysed quantiatively based on publicly available data. In addition, Gaussian Processes
are used for spatial&amp;nbsp;predictions.&lt;/p&gt;
</summary><content type="html">&lt;p&gt;In this text, I attempt to analyse the parking situation in Marburg - the city I am currently living in. Moving through cities
these days, traffic is a big aspect as one is surrounded by cars at all times. When traffic is not flowing, this traffic
typically parks. Hence, my motivation to study the parking situation in Marburg: what are the cars in Marburg doing when not&amp;nbsp;driving?&lt;/p&gt;
&lt;p&gt;This article is mostly about quantitative analyses based on (sort of) publicly available data. The city of Marburg maintains a system that
summarises the currently free parking spots on a website. This system can be accessed under the following website: &lt;a class="reference external" href="https://pls.marburg.de/"&gt;https://pls.marburg.de/&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If you are curious about the analyses and corresponding figures, then please read on: first I give an overview
about the data acquisition process. This is for you to understand what data I am actually using and how I got it. Second, I
continue with the actual analyses that covers analytics as well as&amp;nbsp;predictions.&lt;/p&gt;
&lt;div class="section" id="data-acquisition"&gt;
&lt;h2&gt;Data&amp;nbsp;acquisition&lt;/h2&gt;
&lt;p&gt;I acquired the parking data in Marburg with a set of programming tools. The official &amp;#8220;Parkleitsystem Marburg&amp;#8221;,
roughly translated as &amp;#8220;parking direction system Marburg&amp;#8221;, is used as data source. It is available online at &lt;a class="reference external" href="https://pls.marburg.de/"&gt;https://pls.marburg.de/&lt;/a&gt;
and shown below in Fig. 1 for&amp;nbsp;reference.&lt;/p&gt;
&lt;div class="figure"&gt;
&lt;a class="reference external image-reference" href="http://lellep.xyz/blog/images/parking_in_marburg/0_data_acquisition/pls_website.png"&gt;&lt;img alt="" src="http://lellep.xyz/blog/images/parking_in_marburg/0_data_acquisition/pls_website.png" style="width: 600px;" /&gt;&lt;/a&gt;
&lt;p class="caption"&gt;Figure 1: Screenshot of the official website maintained by the city of Marburg, &lt;a class="reference external" href="https://pls.marburg.de/"&gt;https://pls.marburg.de/&lt;/a&gt;,
as of 02/26/2020. This website serves as my data source. This screenshot shows the available data: the free parking spots
for all parking decks, links to the positions of the parking decks, the maximal vehicle height allowances and the current
data timestamp. The data is updated every five&amp;nbsp;minutes.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;The city website is updated every five minutes and lists parking decks spread across Marburg. These parking decks
comprise popular shopping locations and places, such&amp;nbsp;as:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Ahrens&lt;/li&gt;
&lt;li&gt;City parking&amp;nbsp;deck&lt;/li&gt;
&lt;li&gt;Erlenring-Center&lt;/li&gt;
&lt;li&gt;FurthstraÃe&lt;/li&gt;
&lt;li&gt;FurthstraÃe -&amp;nbsp;Parkdeck&lt;/li&gt;
&lt;li&gt;Hauptbahnhof&lt;/li&gt;
&lt;li&gt;Lahncenter&lt;/li&gt;
&lt;li&gt;Marktdreieck&lt;/li&gt;
&lt;li&gt;Marktdreieck -&amp;nbsp;Parkdeck&lt;/li&gt;
&lt;li&gt;Oberstadt&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For each of the parking decks, a number of data is&amp;nbsp;given:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Column &amp;#8220;&lt;span class="caps"&gt;PARKHAUS&lt;/span&gt;&amp;#8221;: The name of the parking&amp;nbsp;deck.&lt;/li&gt;
&lt;li&gt;Column &amp;#8220;&lt;span class="caps"&gt;FREI&lt;/span&gt;&amp;#8221;: The number of free parking&amp;nbsp;spots.&lt;/li&gt;
&lt;li&gt;Column &amp;#8220;&lt;span class="caps"&gt;ROUTE&lt;/span&gt;&amp;#8221;: A Google Maps link to the parking deck&amp;nbsp;location.&lt;/li&gt;
&lt;li&gt;Column &amp;#8220;max. EinfahrtshÃ¶he&amp;#8221;: The permitted vehicle&amp;nbsp;height.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This website and its content is used as data source for this study. The software used for data acquisition is written
in &lt;a class="reference external" href="https://www.python.org"&gt;Python&lt;/a&gt; and uses &lt;a class="reference external" href="https://scrapy.org"&gt;Scrapy&lt;/a&gt; to download the data from the website.
Scrapy also stores the data in a machine readable format to facilitate the post processing and analysis steps. The whole
software stack runs as a &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Docker_(software)"&gt;Docker container&lt;/a&gt; on a small
&lt;a class="reference external" href="https://en.wikipedia.org/wiki/Linux"&gt;Linux&lt;/a&gt; server. The data is saved every three minutes in order to subsample
the website update interval of five minutes. Note that this time scale is chosen as to have sufficiently dense
data points but not to overload the website servers - in particular the latter aspect should be given high priority
when working on projects as the one in this study. Since only the table given on the city website is processed and
stored, the storage requirements for the Linux server are minimal. Figure 2 summarises the data acquisition&amp;nbsp;pipeline.&lt;/p&gt;
&lt;div class="figure"&gt;
&lt;a class="reference external image-reference" href="http://lellep.xyz/blog/images/parking_in_marburg/0_data_acquisition/download_structure.svg"&gt;&lt;img alt="" src="http://lellep.xyz/blog/images/parking_in_marburg/0_data_acquisition/download_structure.png" style="width: 600px;" /&gt;&lt;/a&gt;
&lt;p class="caption"&gt;Figure 2: The data acquisition pipeline as described in the main text. The &amp;#8220;data for analysis&amp;#8221;, marked by a green
rectangle, is used for all subsequent data analysis&amp;nbsp;steps.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;The analysis pipeline is also written in Python. It uses the &lt;a class="reference external" href="https://www.scipy.org/about.html"&gt;Scientific computing Python stack&lt;/a&gt;.
In particular, the &lt;a class="reference external" href="https://pandas.pydata.org"&gt;Pandas&lt;/a&gt; Python package has been used extensively to arrange and evaluate
the data. The &amp;#8220;data for analysis&amp;#8221; shown in Fig. 2 is exactly one such
&lt;a class="reference external" href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html"&gt;Pandas DataFrame&lt;/a&gt;. The data structure for the
analysis is a table with timestamps along the rows and the parking decks along the columns, as shown in Fig. 3. Over the course
of the data acquisition period, I accumulated around 100,000 snapshots of the&amp;nbsp;website.&lt;/p&gt;
&lt;div class="figure"&gt;
&lt;a class="reference external image-reference" href="http://lellep.xyz/blog/images/parking_in_marburg/0_data_acquisition/data_format.svg"&gt;&lt;img alt="" src="http://lellep.xyz/blog/images/parking_in_marburg/0_data_acquisition/data_format.png" style="width: 350px;" /&gt;&lt;/a&gt;
&lt;p class="caption"&gt;Figure 3: The data format that is used for the analysis. The data is appended to the table as time passes. The table cells
contain the number of free parking spots at a given time and for a given parking deck. The red arrow shows how the
accumulative data is obtained: all values per row are added up to get the overall number of free parking spots per&amp;nbsp;timestamp.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="analysis-of-parking-situation-in-marburg"&gt;
&lt;h2&gt;Analysis of parking situation in&amp;nbsp;Marburg&lt;/h2&gt;
&lt;p&gt;The data analysis is divided into four parts. We start with an introduction to verify that our data is reasonable. The second and
third parts analyse the parking demand as summed over all parking decks in Marburg and for each parking deck separately, respectively.
While the second part only takes temporal information into account, the third part also takes spatio-temporal information into
account. Finally, the last part uses a machine learning prediction method for spatial interpolation that comes with the benefit of
returning uncertainty measures about its&amp;nbsp;predictions.&lt;/p&gt;
&lt;div class="section" id="introduction"&gt;
&lt;h3&gt;Introduction&lt;/h3&gt;
&lt;p&gt;This introduction serves the purpose of getting a very first hold of the acquired data. Here, we will look into the parking deck locations
and how the metric that quantifies &amp;#8220;parking demand&amp;#8221; is computed. It turns out that the data preprocessing steps that I present in this section
are necessary in order to correct corrupted data from the&amp;nbsp;website.&lt;/p&gt;
&lt;p&gt;Each of the snapshots consists of a timestamp, the number of free spots, the corresponding colour, the maximal vehicle height and a
Google Maps link. The latter two are confirmed to remain unchanged throughout the whole dataset for each parking deck and the link is
used to derive the parking deck locations. The locations that are linked in the table are parsed from the correponding &lt;span class="caps"&gt;URL&lt;/span&gt; and shown in
Fig. 4 by the red markers. It turns out that the coordinates obtained from the links on the website are wrong. It seems that Google Maps
corrects for that automatically and redirects to the correct coordinates. I searched for the correct coordinates and indicated them by
green markers in Fig.&amp;nbsp;4.&lt;/p&gt;
&lt;div&gt;
    &lt;iframe src="images/parking_in_marburg/1_data_analysis/0_intro/0_parkhaus_locations.html"
            width="800"
            height="450"
            frameborder="0"
            style="border: 0; margin: 0 auto; display:block; margin-bottom: 10px; max-width: 100%"
            allowfullscreen=""&gt;
    &lt;/iframe&gt;
&lt;/div&gt;
&lt;div class="figure"&gt;
    &lt;p class="caption"&gt;
        Figure 4: The parking deck locations. The incorrect locations as given on the website
        are marked as red markers. Dashed lines connect these incorrect locations to their
        correct locations, indicated as green&amp;nbsp;markers.
    &lt;/p&gt;
&lt;/div&gt;&lt;p&gt;These correct coordinates are used for a quick experiment to warm up a little bit more. Using the &lt;a class="reference external" href="https://www.openstreetmap.org/#map=17/48.80418/2.12230"&gt;OpenStreetMap&lt;/a&gt;, I compile a list of all restaurants, pubs, &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Beer_garden"&gt;Biergarten&lt;/a&gt;
and &lt;a class="reference external" href="https://de.wikipedia.org/wiki/Kneipe"&gt;Kneipen&lt;/a&gt; in Marburg. The list comprises of classical pubs in Marburg like the &amp;#8220;Sudhaus&amp;#8221;
and &amp;#8220;Quod&amp;#8221; but also incoporates the &amp;#8220;Mensa&amp;#8221;, taking a whopping 153 items into account. For each of the parking decks, the distance to all of the
restaurants/pubs is computed and summed up. The accumulated distances are shown in Fig. 5 and guide you to the parking deck that you
should choose whenever you are hungry: pick &amp;#8220;oberstadt&amp;#8221;, &amp;#8220;lahncenter&amp;#8221;, &amp;#8220;city&amp;#8221; or &amp;#8220;ahrens&amp;#8221; if you are particularly hungry as they have
the smallest accumulated distance to restaurants and&amp;nbsp;pubs.&lt;/p&gt;
&lt;div class="figure"&gt;
&lt;a class="reference external image-reference" href="http://lellep.xyz/blog/images/parking_in_marburg/1_data_analysis/0_intro/1_POIs.png"&gt;&lt;img alt="" src="http://lellep.xyz/blog/images/parking_in_marburg/1_data_analysis/0_intro/1_POIs.png" style="width: 600px;" /&gt;&lt;/a&gt;
&lt;p class="caption"&gt;Figure 5: The accumulated distances to places like restaurants and pubs for each of the parking decks. The type of place is encoded
as colour. The parking decks with the smallest accumulated distances to restaurants and pubs are &amp;#8220;oberstadt&amp;#8221;, &amp;#8220;lahncenter&amp;#8221;, &amp;#8220;city&amp;#8221;
and&amp;nbsp;&amp;#8220;ahrens&amp;#8221;.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;With the parking deck positions in place, let&amp;#8217;s focus on the metric. The measure of &amp;#8220;parking demand&amp;#8221; is quantified here as the number of
used parking spots. However, the website only states the number of free parking spots. The capacity of each parking deck is calculated
as maximum of the free parking spots. To obtain the number of used parking spots, the number of free parking spots are subtracted from
the capacity. The capacities determined by this procedure are shown in the corresponding column of the following&amp;nbsp;table:&lt;/p&gt;
&lt;table border="1" class="docutils"&gt;
&lt;colgroup&gt;
&lt;col width="37%" /&gt;
&lt;col width="31%" /&gt;
&lt;col width="31%" /&gt;
&lt;/colgroup&gt;
&lt;thead valign="bottom"&gt;
&lt;tr&gt;&lt;th class="head"&gt;Parking deck&lt;/th&gt;
&lt;th class="head"&gt;Determined capacity&lt;/th&gt;
&lt;th class="head"&gt;Documented capacity&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td&gt;ahrens&lt;/td&gt;
&lt;td&gt;213&lt;/td&gt;
&lt;td&gt;225&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;city&lt;/td&gt;
&lt;td&gt;195&lt;/td&gt;
&lt;td&gt;160&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;erlenring-center&lt;/td&gt;
&lt;td&gt;402&lt;/td&gt;
&lt;td&gt;409&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;furthstraÃe&lt;/td&gt;
&lt;td&gt;118&lt;/td&gt;
&lt;td&gt;204&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;furthstraÃe - parkdeck&lt;/td&gt;
&lt;td&gt;97&lt;/td&gt;
&lt;td&gt;n.a.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;hauptbahnhof&lt;/td&gt;
&lt;td&gt;264&lt;/td&gt;
&lt;td&gt;288&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;lahncenter&lt;/td&gt;
&lt;td&gt;170&lt;/td&gt;
&lt;td&gt;168&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;marktdreieck&lt;/td&gt;
&lt;td&gt;190&lt;/td&gt;
&lt;td&gt;280&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;marktdreieck - parkdeck&lt;/td&gt;
&lt;td&gt;97&lt;/td&gt;
&lt;td&gt;n.a.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;oberstadt&lt;/td&gt;
&lt;td&gt;209&lt;/td&gt;
&lt;td&gt;235&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;These empirically determined values can be compared to the ones
&lt;a class="reference external" href="https://www.marburg-tourismus.de/portal/seiten/parken-900000695-1000000.html"&gt;documented officially&lt;/a&gt;, as shown in the table column
&amp;#8220;documented capacity&amp;#8221;. Apparently, the two sets of numbers are close to each other. Since the empirically computed parking capacities
are more granular (e.g. they distinguish between &amp;#8220;Marktdreieck&amp;#8221; and &amp;#8220;Marktdreieck - Parkdeck&amp;#8221;) and seem to be more up-to-date (empirically,
the &amp;#8220;City&amp;#8221; parking deck was found to have had 195 free parking spots at maximum despite only having 160 parking spots as documented
officially), I will be using the empirically determined capacities for the analyses that I show in the&amp;nbsp;following.&lt;/p&gt;
&lt;p&gt;With the coordinates and used parking spots determined, we turn towards the main analysis. This main analysis begins with the accumulative&amp;nbsp;signal.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="accumulative-parking-analysis"&gt;
&lt;h3&gt;Accumulative parking&amp;nbsp;analysis&lt;/h3&gt;
&lt;p&gt;The accumulative data is obtained as shown by the red arrow in Fig. 3: the columns for all parking decks are summed up to yield the accumulated
number of used parking&amp;nbsp;spots.&lt;/p&gt;
&lt;p&gt;Given the timestamps of the data, the number of used parking spots can be plotted against time. Since the data acqusition time of 3min is
quite fast on the scale of the data collection process - namely month -, the data is resampled to hours, days and weeks, as shown in Fig.&amp;nbsp;6.&lt;/p&gt;
&lt;div class="figure"&gt;
&lt;a class="reference external image-reference" href="http://lellep.xyz/blog/images/parking_in_marburg/1_data_analysis/1_joint/0_cumulative_signal.png"&gt;&lt;img alt="" src="http://lellep.xyz/blog/images/parking_in_marburg/1_data_analysis/1_joint/0_cumulative_signal.png" style="width: 600px;" /&gt;&lt;/a&gt;
&lt;p class="caption"&gt;Figure 6: The used parking spots as summed over all parking decks against time. The data is resampled to hours, days and weeks, as
shown by the three lines. These resamples highlight trends in the&amp;nbsp;data.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;The green line shows the weekly average. It drops during the time between Christmas and New Year&amp;#8217;s Eve. Furthermore, the regularity of the
data becomes obvious. There seem to be two types of periodicity: first, the periodicity per day (as hardly visible
by the data resampled to one hour) and second, periodicity per week (as clearly visible by the data resampled to one day). Despite these obvious
facts, the figure might be nice to look at but doesn&amp;#8217;t quantify the periodicities&amp;nbsp;further.&lt;/p&gt;
&lt;p&gt;The autocorrelation of Fig. 6 is computed to quantify the periodicity. The &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Autocorrelation"&gt;autocorrelation&lt;/a&gt;
function measures how similar a signal is to itself by shifting it by some time delay that make up the x-axis of autocorrelation plots.
For time delays at which the autocorrelation function has maxima, the signal is similar to itself. Hence,
periodicity can be quantified by exactly these maxima of the autocorrelation function. Figure 7 shows the autocorrelation function of the parking
demand in&amp;nbsp;Marburg.&lt;/p&gt;
&lt;div class="figure"&gt;
&lt;a class="reference external image-reference" href="http://lellep.xyz/blog/images/parking_in_marburg/1_data_analysis/1_joint/1_autocorrelation.png"&gt;&lt;img alt="" src="http://lellep.xyz/blog/images/parking_in_marburg/1_data_analysis/1_joint/1_autocorrelation.png" style="width: 600px;" /&gt;&lt;/a&gt;
&lt;p class="caption"&gt;Figure 7: The autocorrelation of the accumulatively used parking spots. The period of seven days is marked by a red&amp;nbsp;line.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;As suggested by the accumulative signal in Fig. 6, the autocorrelation shown in Fig. 7 peaks at seven days. This confirms that the signal has a period
of seven days. The daily periodicity is not visible in this plot as it is based on the daily resample of the data; the initial small peak at the shift
value of one in Fig. 7 is due to the fact that this value corresponds exactly to the sampling frequency of the resampled signal and, by that, does not
carry any relevant information regarding the periodicity in the signal. All other peaks correspond to multiples of the identified 7-day&amp;nbsp;periodicity.&lt;/p&gt;
&lt;p&gt;Finally, to understand the full scope of the periodicity of the signal, I evaluated the day-hour-histogram. This type of histogram is used to visualise
the number of used parking spots in Marburg against time and day of the week. This makes up a two dimensional matrix, as shown in Fig.&amp;nbsp;8.&lt;/p&gt;
&lt;div class="figure"&gt;
&lt;a class="reference external image-reference" href="http://lellep.xyz/blog/images/parking_in_marburg/1_data_analysis/1_joint/2_day_time_histogram.png"&gt;&lt;img alt="" src="http://lellep.xyz/blog/images/parking_in_marburg/1_data_analysis/1_joint/2_day_time_histogram.png" style="width: 600px;" /&gt;&lt;/a&gt;
&lt;p class="caption"&gt;Figure 8: The average of the used parking spots against time and day. Summing along rows and columns results in the daily and hourly
usage histograms, respectively. Yellow corresponds to high and blue corresponds to low values, as quantified by the&amp;nbsp;colourbar.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;It becomes obvious that the peak hours of parking demand during the working week are between 11am and 4pm. Also, notably, the weekends are
less busy as people are probably not going into the city by car. On Saturdays, the peak hours in parking demand are shorter, only from around 12pm to
3pm. On Sundays, there is significantly less parking demand in Marburg as compared to all other six days. Interestingly, the relaxed Sunday mood
smears into Monday mornings, as these are much less busy than regular mornings during the working week. Finally, it can be observed that even at
late nights, like 10pm to 4am, there are still cars using the parking&amp;nbsp;decks.&lt;/p&gt;
&lt;p&gt;Now that we know the periodicity of the parking demand in Marburg, let&amp;#8217;s focus on all of the parking decks&amp;nbsp;separately.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="separate-parking-deck-analysis"&gt;
&lt;h3&gt;Separate parking deck&amp;nbsp;analysis&lt;/h3&gt;
&lt;p&gt;Now we turn to the more detailed analyses that take the different parking decks into account. First, Fig. 9 shows the parking demand against
time for each parking deck&amp;nbsp;separately.&lt;/p&gt;
&lt;div class="figure"&gt;
&lt;a class="reference external image-reference" href="http://lellep.xyz/blog/images/parking_in_marburg/1_data_analysis/2_separately/0_single_signals.png"&gt;&lt;img alt="" src="http://lellep.xyz/blog/images/parking_in_marburg/1_data_analysis/2_separately/0_single_signals.png" style="width: 600px;" /&gt;&lt;/a&gt;
&lt;p class="caption"&gt;Figure 9: The parking demand against time, similar to Fig. 6. Here, however, the accumulative signal is split into the contributions from
each parking&amp;nbsp;deck.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Despite being overloaded with information, there are a few aspects that this figure points towards. First, the signals seem to be periodic as well
and second, the parking decks seem to vary significantly in how many parking spots are used. The integral parking demand quantifies exactly that:
it measures how many parking spots have been provided by a parking deck throughout the whole measurement period. Figure 10 shows the results&amp;nbsp;thereof.&lt;/p&gt;
&lt;div class="figure"&gt;
&lt;a class="reference external image-reference" href="http://lellep.xyz/blog/images/parking_in_marburg/1_data_analysis/2_separately/2_integral_parking_demand.png"&gt;&lt;img alt="" src="http://lellep.xyz/blog/images/parking_in_marburg/1_data_analysis/2_separately/2_integral_parking_demand.png" style="width: 600px;" /&gt;&lt;/a&gt;
&lt;p class="caption"&gt;Figure 10: Integral parking demand of all parking decks. These numbers are obtained by summing up the number of used parking spots per each
parking deck over the whole measurement period. The blue bars in the bottom show the integral parking demand during working days and the stacked
orange bars show the parking demand during the weekends for each parking deck. The integral parking demand is normalised to the maximal
integral parking demand across all parking&amp;nbsp;decks.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;The integral parking demand shows that the &amp;#8220;Erlenring&amp;#8221; parking deck is by far the most used parking deck. The second most important parking deck,
&amp;#8220;Lahncenter&amp;#8221;, provides around half of the parking spots that &amp;#8220;Erlenring&amp;#8221; provides. The proportion of parking spots provided on weekends compared
to the overall number of provided parking decks is roughly equal for almost all parking decks. Here, only &amp;#8220;Marktdreieck - Parkdeck&amp;#8221; differs as
this parking deck provides significantly fewer parking spots on&amp;nbsp;weekends.&lt;/p&gt;
&lt;p&gt;The integral parking demand can be given an additional temporal information by rendering a video that takes time into account. The following video
shows the parking deck usage against passing hours. The video shows the ratio of parking spots that are used with the hour and date running in the
title of the figure. As before, the number of used parking decks is normalised to the maximal usage across all parking decks and, additionally,
all&amp;nbsp;times.&lt;/p&gt;
&lt;div style="margin: 0px auto; text-align: center;"&gt;
    &lt;iframe width="560"
            height="315"
            src="https://www.youtube.com/embed/GvyMukqKLM4"
            frameborder="0"
            allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture"
            style="border: 0; margin: 0 auto; display:block; margin-bottom: 10px; max-width: 100%"
            allowfullscreen&gt;
    &lt;/iframe&gt;
&lt;/div&gt;
&lt;br/&gt;&lt;p&gt;Clearly, this video visualises the periodicity in the signal. The parking deck bars disappear when there is no data - certain parking decks close
down during the night and some days of the weekend. Most of the parking decks reach 100% occupancy and then decrease to smaller values below 5%
during the night. The notable exceptions to this observation are the parking decks &amp;#8220;Lahncenter&amp;#8221; and &amp;#8220;Erlenring&amp;#8221; which only decrease to around 40%
to 50% occupancy at night. That might explain the previous observation in Fig. 8 of cars that remain parked during night. In the beginning of the
video there is some data missing as my data acquisition pipeline broke down during that&amp;nbsp;time.&lt;/p&gt;
&lt;p&gt;The dependence on time is studied further. Figure 11 shows the histograms of used parking spots for each parking decks separately. Not only that,
it also shows histograms thereof that depend on the time of the&amp;nbsp;day.&lt;/p&gt;
&lt;div class="figure"&gt;
&lt;a class="reference external image-reference" href="http://lellep.xyz/blog/images/parking_in_marburg/1_data_analysis/2_separately/1_temporal_histograms.png"&gt;&lt;img alt="" src="http://lellep.xyz/blog/images/parking_in_marburg/1_data_analysis/2_separately/1_temporal_histograms.png" style="width: 600px;" /&gt;&lt;/a&gt;
&lt;p class="caption"&gt;Figure 11: Histograms of used parkings spots conditioned on time of the day. Each subplot corresponds to one parking deck. The time-independent
histogram is shown in blue. The histograms of colours yellow, green and red correspond to mornings, noons and evenings as defined by the hours
between 7am to 9am, 11am to 1pm and 4:30pm to 6:30pm, respectively. Each histogram is normalised independently for a better visual&amp;nbsp;appearance.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;The temporal histograms shown in Fig. 11 visualises a number of results. For some of the parking decks it is clearly visible how the peak of parking demand
shifts with time: parking decks like &amp;#8220;ahrens&amp;#8221;, &amp;#8220;oberstadt&amp;#8221;, &amp;#8220;marktdreieck&amp;#8221;, &amp;#8220;marktdreieck - parkdeck&amp;#8221;, &amp;#8220;furthstraÃe&amp;#8221; or &amp;#8220;hauptbahnhof&amp;#8221; all show how
there is little parking demand in the mornings, a maximal parking demand around noon and a decaying parking demand in the evening. Contrary, parking
decks like &amp;#8220;city&amp;#8221;, &amp;#8220;ehrlenring-center&amp;#8221; or &amp;#8220;lahncenter&amp;#8221; do not seem to depend on time as&amp;nbsp;much.&lt;/p&gt;
&lt;p&gt;After these analyses about the acquired data, we finally turn towards&amp;nbsp;predictions.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="predictive-analysis"&gt;
&lt;h3&gt;Predictive&amp;nbsp;analysis&lt;/h3&gt;
&lt;p&gt;As last part of this article, I attempt a predictive analysis of the parking data in Marburg. The parking decks indicate parking
demand at their locations. With the following spatial prediction, I would like to forecast parking demand where there are no parking decks&amp;nbsp;available.&lt;/p&gt;
&lt;p&gt;Since I am also interested in the uncertainties in the predictions, I use &lt;a class="reference external" href="http://www.gaussianprocess.org/gpml/chapters/RW2.pdf"&gt;Gaussian Process Regression&lt;/a&gt;
(&lt;span class="caps"&gt;GPR&lt;/span&gt;) for the spatial predictions. &lt;span class="caps"&gt;GPR&lt;/span&gt; uses &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Gaussian_process"&gt;Gaussian Processes&lt;/a&gt; (GPs), which themselves generalise
&lt;a class="reference external" href="https://en.wikipedia.org/wiki/Multivariate_normal_distribution"&gt;multivariate Gaussian distributions&lt;/a&gt; to function space. Being a Bayesian method,
they return not only a prediction but also the uncertainty of the&amp;nbsp;prediction.&lt;/p&gt;
&lt;p&gt;Despite that &lt;span class="caps"&gt;GPR&lt;/span&gt; is a non-parametric statistical method, it needs hyperparameters. While I do not want to give an introduction to &lt;span class="caps"&gt;GPR&lt;/span&gt; in this
article, the analysis details are noted here for the sake of a transparent analysis. Please consult the links provided before and make sure to focus
on the amazing book by &lt;em&gt;Rasmussen et al&lt;/em&gt; to understand the following technial&amp;nbsp;details:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Contrary to the typically chosen zero-mean &lt;span class="caps"&gt;GP&lt;/span&gt; prior, I use the mean of the data as &lt;span class="caps"&gt;GP&lt;/span&gt; prior&amp;nbsp;mean.&lt;/li&gt;
&lt;li&gt;A &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Radial_basis_function_kernel"&gt;radial basis function kernel&lt;/a&gt; is used as correlation function of the &lt;span class="caps"&gt;GP&lt;/span&gt;&amp;nbsp;prior.&lt;/li&gt;
&lt;li&gt;The kernel hyperparameters, magnitude and length scale, are set heuristically based on visual fit quality and the characteristic length scale of&amp;nbsp;Marburg.&lt;/li&gt;
&lt;li&gt;Very nearby parking decks (&amp;#8220;marktdreieck&amp;#8221; and &amp;#8220;marktdreieck - parkdeck&amp;#8221; as well as &amp;#8220;furthstraÃe&amp;#8221; and &amp;#8220;furthstraÃe - parkdeck&amp;#8221;) are merged in order
to avoid&amp;nbsp;discontinuities.&lt;/li&gt;
&lt;li&gt;I use a noise-free &lt;span class="caps"&gt;GP&lt;/span&gt; prior as the integer measurements from the website do not come with&amp;nbsp;noise.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;With these technical details in place, it is time to look at the &lt;span class="caps"&gt;GPR&lt;/span&gt; results. The following video shows the parking deck usage averaged over the whole
measurement period. It is a 3D plot with the plane as geographical coordinates of Marburg, the height of the upper subplot as predicted parking deck
usage and the height of the lower subplot as prediction uncertainty of the parking deck&amp;nbsp;usage.&lt;/p&gt;
&lt;div style="margin: 0px auto; text-align: center;"&gt;
    &lt;iframe width="560"
            height="315"
            src="https://www.youtube.com/embed/lg4zYv09nxA"
            frameborder="0"
            allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture"
            style="border: 0; margin: 0 auto; display:block; margin-bottom: 10px; max-width: 100%"
            allowfullscreen&gt;
    &lt;/iframe&gt;
&lt;/div&gt;
&lt;br/&gt;&lt;p&gt;The usage values of the parking decks are indicated with black dots. The maximum of the prediction, indicated as height as well as in yellow colour, is
located close to the erlenring parking deck. As expected on account of the &lt;span class="caps"&gt;GPR&lt;/span&gt; algorithm, the prediction uncertainties decrease close to the measurement
positions. In order to fully see the spatial predictions, the 3D plots are rotated. At the end of the video, the viewport is rotated to the top&amp;nbsp;view.&lt;/p&gt;
&lt;p&gt;The second video uses exactly that top down view to visualise the spatial predictions. However, it also introduces a temporal component by showing
the spatial predictions as days pass. The data shown is the daily average. On the left of the following video, the colour encoded top-down view as
introduced in the previous video is shown. The black dots correspond to the locations of the parking decks that served as training data. The red dots,
however, correspond to
points-of-interest (POIs) between the parking decks. Hence, the &lt;span class="caps"&gt;GPR&lt;/span&gt; is used to compute the predicted parking demand at these POIs. The right subplot
shows the corresponding values of these POIs together with their names: I evaluated the parking demand as fitted by the &lt;span class="caps"&gt;GPR&lt;/span&gt; at the &amp;#8220;mensa&amp;#8221;, &amp;#8220;physik&amp;#8221;,
&amp;#8220;&lt;span class="caps"&gt;UB&lt;/span&gt;&amp;#8221; (university library), &amp;#8220;bahnhof&amp;#8221; and &amp;#8220;kino&amp;#8221; in Marburg. These predictions do come with uncertainies, but they are very small. If you look very
closely, you might spot the error bars in right&amp;nbsp;subplot.&lt;/p&gt;
&lt;div style="margin: 0px auto; text-align: center;"&gt;
    &lt;iframe width="560"
            height="315"
            src="https://www.youtube.com/embed/axSnq4vRl_E"
            frameborder="0"
            allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture"
            style="border: 0; margin: 0 auto; display:block; margin-bottom: 10px; max-width: 100%"
            allowfullscreen&gt;
    &lt;/iframe&gt;
&lt;/div&gt;
&lt;br/&gt;&lt;p&gt;This video shows that the location &amp;#8220;mensa&amp;#8221; is the place with the highest parking demand. &amp;#8220;Physik&amp;#8221;, &amp;#8220;&lt;span class="caps"&gt;UB&lt;/span&gt;&amp;#8221; and &amp;#8220;bahnhof&amp;#8221; have roughly the same parking
demand and &amp;#8220;kino&amp;#8221; fluctuates the most across the days that are&amp;nbsp;shown.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="conclusion"&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;In this article I showed how publicly available parking data in Marburg is saved, analysed and finally used for spatial predictions. The
statistical analysis comprises a few aspects that are interesting for both, people looking for free parking spots as well as the city of Marburg.
This analysis is interesting for the city of Marburg because the usage statistics of
the parking decks could be utilised to ultimately improve the parking situation in Marburg, e.g. by incorporating load balancing or by re-thinking
the necessity of more or less parking decks. The spatial prediction yields statements about where particularly many or particularly few parking spots
in Marburg are&amp;nbsp;required.&lt;/p&gt;
&lt;p&gt;You might ask why I compiled this study. First, I like to do such things. Second, I believe that &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Open_data"&gt;open data&lt;/a&gt;
can contribute to a better quality of the
lives of all of us as existing systems can be analysed and optimised. This is daily business in the corporate sector but has not reached the public sector, yet. This article is to foster the spirit of open data in Marburg in the hope that open data improves the quality of lives in Marburg in the&amp;nbsp;future.&lt;/p&gt;
&lt;p&gt;The more open data there is available, the more open data fans such as me can help to compile similar analyses for the city of Marburg. Dear Marburg,
start to provide us with exciting open data!&amp;nbsp;:-)&lt;/p&gt;
&lt;p&gt;&lt;em&gt;If you have questions about this article or would like to know more about the analyses, please feel free to contact me via&lt;/em&gt;
&lt;a class="reference external" href="mailto:martin.lellep+blog&amp;#64;gmail.com"&gt;email&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
</content></entry><entry><title>Internet-capable woodenÂ lamp</title><link href="http://lellep.xyz/blog/internet-capable-wooden-lamp.html" rel="alternate"></link><published>2019-11-03T00:00:00+01:00</published><updated>2019-11-03T00:00:00+01:00</updated><author><name>Martin Lellep</name></author><id>tag:lellep.xyz,2019-11-03:/blog/internet-capable-wooden-lamp.html</id><summary type="html">&lt;p class="first last"&gt;I built a wooden lamp around the Sonoff Basic IoT&amp;nbsp;module.&lt;/p&gt;
</summary><content type="html">&lt;p&gt;This article describes how I built an internet-capable lamp. The housing and mechanical parts were made with wood working tools, a 3D printer and a laser cutter. The electrical control unit is realised with a &lt;a class="reference external" href="https://sonoff.tech/product/wifi-diy-smart-switches/basicr2"&gt;Sonoff Basic&lt;/a&gt; IoT module that can be controlled through an&amp;nbsp;app.&lt;/p&gt;
&lt;div class="section" id="the-result"&gt;
&lt;h2&gt;The&amp;nbsp;result&lt;/h2&gt;
&lt;p&gt;The final lamp is shown&amp;nbsp;below.&lt;/p&gt;
&lt;div class="figure"&gt;
&lt;a class="reference external image-reference" href="http://lellep.xyz/blog/images/wooden_IoT_lamp/hr/0_final_result_colorful.jpg"&gt;&lt;img alt="" src="http://lellep.xyz/blog/images/wooden_IoT_lamp/lr/0_final_result_colorful.jpg" style="width: 500px;" /&gt;&lt;/a&gt;
&lt;p class="caption"&gt;The result of the&amp;nbsp;project.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="the-build-process-in-pictures"&gt;
&lt;h2&gt;The build process in&amp;nbsp;pictures&lt;/h2&gt;
&lt;p&gt;In the following, you can find pictures that document the build process in a top-down approach: the finished product is shown at first and the steps backward in time to arrive at the final product are documented subsequently. The last picture shows the final lamp&amp;nbsp;again.&lt;/p&gt;
&lt;p&gt;Since pictures say more than words, here we go with the&amp;nbsp;pictures:&lt;/p&gt;
&lt;div class="figure"&gt;
&lt;a class="reference external image-reference" href="http://lellep.xyz/blog/images/wooden_IoT_lamp/hr/1_perspective_painted.jpg"&gt;&lt;img alt="" src="http://lellep.xyz/blog/images/wooden_IoT_lamp/lr/1_perspective_painted.jpg" style="width: 500px;" /&gt;&lt;/a&gt;
&lt;p class="caption"&gt;The final lamp while it is screwed&amp;nbsp;together.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="figure"&gt;
&lt;a class="reference external image-reference" href="http://lellep.xyz/blog/images/wooden_IoT_lamp/hr/2_side_view_painted.jpg"&gt;&lt;img alt="" src="http://lellep.xyz/blog/images/wooden_IoT_lamp/lr/2_side_view_painted.jpg" style="width: 500px;" /&gt;&lt;/a&gt;
&lt;p class="caption"&gt;Side view of the final lamp with the lid slightly displaced to show how the lid attaches to the&amp;nbsp;bottom.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="figure"&gt;
&lt;a class="reference external image-reference" href="http://lellep.xyz/blog/images/wooden_IoT_lamp/hr/3_overview_inner.jpg"&gt;&lt;img alt="" src="http://lellep.xyz/blog/images/wooden_IoT_lamp/lr/3_overview_inner.jpg" style="width: 500px;" /&gt;&lt;/a&gt;
&lt;p class="caption"&gt;Detached lid to show the electrical&amp;nbsp;wiring.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="figure"&gt;
&lt;a class="reference external image-reference" href="http://lellep.xyz/blog/images/wooden_IoT_lamp/hr/4_overview.jpg"&gt;&lt;img alt="" src="http://lellep.xyz/blog/images/wooden_IoT_lamp/lr/4_overview.jpg" style="width: 500px;" /&gt;&lt;/a&gt;
&lt;p class="caption"&gt;All parts of the lamp layed out next to each other. The box to the right was made with wood working tools. The remaining wooden pieces were laser cut and most of the white plastic parts were 3D printed from &lt;span class="caps"&gt;PLA&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="figure"&gt;
&lt;a class="reference external image-reference" href="http://lellep.xyz/blog/images/wooden_IoT_lamp/hr/5_switch.jpg"&gt;&lt;img alt="" src="http://lellep.xyz/blog/images/wooden_IoT_lamp/lr/5_switch.jpg" style="width: 500px;" /&gt;&lt;/a&gt;
&lt;p class="caption"&gt;Close up of the 3D printed mechanical switch. A small toggle switch was soldered on a card board and the white 3D printed parts mount around it to provide a mechanism to toggle the switch easily. The small toggle switch is connected in parallel to the existing surface-mounted switch of the Sonoff Basic. The springs provide decent feedback while pressing the&amp;nbsp;switch.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="figure"&gt;
&lt;a class="reference external image-reference" href="http://lellep.xyz/blog/images/wooden_IoT_lamp/hr/6_lampshade_mounting.jpg"&gt;&lt;img alt="" src="http://lellep.xyz/blog/images/wooden_IoT_lamp/lr/6_lampshade_mounting.jpg" style="width: 500px;" /&gt;&lt;/a&gt;
&lt;p class="caption"&gt;This laser cut circle is mounted around the bulb housing with metal screws. The remaining six holes provide an interface to attach different lamp shades to the lamp in the&amp;nbsp;future.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="figure"&gt;
&lt;a class="reference external image-reference" href="http://lellep.xyz/blog/images/wooden_IoT_lamp/hr/7_bottom_unpainted.jpg"&gt;&lt;img alt="" src="http://lellep.xyz/blog/images/wooden_IoT_lamp/lr/7_bottom_unpainted.jpg" style="width: 500px;" /&gt;&lt;/a&gt;
&lt;p class="caption"&gt;The wooden base prior to painting. The bottom shows the mounting holes for the 3D printed electronics attachments. The four wider holes on the edges provide a mechanism to attach the&amp;nbsp;lid.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="figure"&gt;
&lt;a class="reference external image-reference" href="http://lellep.xyz/blog/images/wooden_IoT_lamp/hr/8_mounting_mechanism.jpg"&gt;&lt;img alt="" src="http://lellep.xyz/blog/images/wooden_IoT_lamp/lr/8_mounting_mechanism.jpg" style="width: 500px;" /&gt;&lt;/a&gt;
&lt;p class="caption"&gt;Close-up of the mounting mechanism of the lid. The wide holes house laser cut wooden pieces with a concentrically aligned M3 nut that has been glued inside these wooden pieces. This way, the lid can be screwed in place, as shown in the second&amp;nbsp;picture.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="figure"&gt;
&lt;a class="reference external image-reference" href="http://lellep.xyz/blog/images/wooden_IoT_lamp/hr/9_electronics_bottom.jpg"&gt;&lt;img alt="" src="http://lellep.xyz/blog/images/wooden_IoT_lamp/lr/9_electronics_bottom.jpg" style="width: 500px;" /&gt;&lt;/a&gt;
&lt;p class="caption"&gt;The electronics mounted to the 3D printed pieces, which, themselves, have been screwed inside the unpainted wooden&amp;nbsp;base.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="figure"&gt;
&lt;a class="reference external image-reference" href="http://lellep.xyz/blog/images/wooden_IoT_lamp/hr/10_electronics_top.jpg"&gt;&lt;img alt="" src="http://lellep.xyz/blog/images/wooden_IoT_lamp/lr/10_electronics_top.jpg" style="width: 500px;" /&gt;&lt;/a&gt;
&lt;p class="caption"&gt;The 3D printed switch is mounted to the lid and reaches into the inner volume of the lamp. The orange-white cables of the switch will be connected to the Sonoff unit. The green-yellow wires power the actual light bulb and thereby carry mains&amp;nbsp;voltage.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="figure"&gt;
&lt;a class="reference external image-reference" href="http://lellep.xyz/blog/images/wooden_IoT_lamp/hr/11_perspective_unpainted.jpg"&gt;&lt;img alt="" src="http://lellep.xyz/blog/images/wooden_IoT_lamp/lr/11_perspective_unpainted.jpg" style="width: 500px;" /&gt;&lt;/a&gt;
&lt;p class="caption"&gt;Assembly of the lamp prior to&amp;nbsp;painting.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="figure"&gt;
&lt;a class="reference external image-reference" href="http://lellep.xyz/blog/images/wooden_IoT_lamp/hr/12_painting.jpg"&gt;&lt;img alt="" src="http://lellep.xyz/blog/images/wooden_IoT_lamp/lr/12_painting.jpg" style="width: 500px;" /&gt;&lt;/a&gt;
&lt;p class="caption"&gt;Painting of the wooden base and the lid. The inner sides are spray-painted in&amp;nbsp;black.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="figure"&gt;
&lt;a class="reference external image-reference" href="http://lellep.xyz/blog/images/wooden_IoT_lamp/hr/13_housing_painted.jpg"&gt;&lt;img alt="" src="http://lellep.xyz/blog/images/wooden_IoT_lamp/lr/13_housing_painted.jpg" style="width: 500px;" /&gt;&lt;/a&gt;
&lt;p class="caption"&gt;Finished painting of the outside. It is coloured in&amp;nbsp;brown.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="figure"&gt;
&lt;a class="reference external image-reference" href="http://lellep.xyz/blog/images/wooden_IoT_lamp/hr/14_final_result.jpg"&gt;&lt;img alt="" src="http://lellep.xyz/blog/images/wooden_IoT_lamp/lr/14_final_result.jpg" style="width: 500px;" /&gt;&lt;/a&gt;
&lt;p class="caption"&gt;The final assembly of the lamp. The power plug goes into the wall and the lamp is connected to the internet via WiFi by using the Sonoff app. After that, it is remotely controllable from anywhere in the&amp;nbsp;world.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="additional-information-of-the-build"&gt;
&lt;h2&gt;Additional information of the&amp;nbsp;build&lt;/h2&gt;
&lt;p&gt;The Sonoff Basic is a WiFi-enabled device that is connected in series to the actuator to control. The Sonoff unit comes at a very competitive price point of around $4 and is, if desired, easy to hack to one&amp;#8217;s needs by flasing a custom firmware. Here, however, I decided to stick to the stock firmware for the time being. While that might change later, the firmware it comes with is sufficient for me at this time and it would be easy to change it later&amp;nbsp;on.&lt;/p&gt;
&lt;p&gt;Hence, the whole exercise of this project is to construct a housing for the Sonoff Basic and to attach a lamp to&amp;nbsp;it.&lt;/p&gt;
&lt;p&gt;I designed the lamp in &lt;span class="caps"&gt;CAD&lt;/span&gt; and incorporated parts made from solid wood, 3D printed plastic parts and laser cut wooden parts. Solid wood is used for the outer box to provide sufficient stability for the lamp. 3D printed plastic parts are used for mechanical parts and mountings of the electronics. Laser cut wooden parts are used as decoration and mechanical parts. Last but not least, the electronics is wired to mains&amp;nbsp;voltage.&lt;/p&gt;
&lt;p&gt;The &lt;span class="caps"&gt;CAD&lt;/span&gt; model is shown below in two&amp;nbsp;visualisations.&lt;/p&gt;
&lt;div class="figure"&gt;
&lt;a class="reference external image-reference" href="http://lellep.xyz/blog/images/wooden_IoT_lamp/hr/15_CAD_realistic.png"&gt;&lt;img alt="" src="http://lellep.xyz/blog/images/wooden_IoT_lamp/lr/15_CAD_realistic.png" style="width: 500px;" /&gt;&lt;/a&gt;
&lt;p class="caption"&gt;Realistic &lt;span class="caps"&gt;CAD&lt;/span&gt; rendering of the 3D model that I drew prior to building the&amp;nbsp;lamp.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="figure"&gt;
&lt;a class="reference external image-reference" href="http://lellep.xyz/blog/images/wooden_IoT_lamp/hr/16_CAD_drawing.png"&gt;&lt;img alt="" src="http://lellep.xyz/blog/images/wooden_IoT_lamp/lr/16_CAD_drawing.png" style="width: 500px;" /&gt;&lt;/a&gt;
&lt;p class="caption"&gt;Simpler &lt;span class="caps"&gt;CAD&lt;/span&gt; rendering of the&amp;nbsp;model.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;The actual construction is documented above in the preceding section by means of&amp;nbsp;pictures.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="conclusion"&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;A wooden lamp around an existing IoT component has been built here. The main features of the lamp&amp;nbsp;are:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;The lamp is not only controllable through an app but there is also a physical switch to trigger it. I made that a key requirement for this lamp project as I wanted to be able to control it by hand as well. The physical switch consists of a 3D printed switch mechanism and a toggle&amp;nbsp;switch.&lt;/li&gt;
&lt;li&gt;The lamp comes with a standard E27 thread for the light bulb. The E27 thread is very popular in Germany as it is used for ceiling lamps so that corresponding light bulbs are easy and cheap to get. I decided to use a &lt;span class="caps"&gt;LED&lt;/span&gt; light bulb for energy and cost&amp;nbsp;efficiency.&lt;/li&gt;
&lt;li&gt;The lamp can be disassembled easily. This way it is easy to, e.g., replace the Sonoff Basic unit or to flash a custom firmware onto it. Furthermore, it is possible to ensure that the mains voltage cable wiring is&amp;nbsp;correct.&lt;/li&gt;
&lt;li&gt;I mounted a ring with 6 holes to be able to modularly attach a lampshade later&amp;nbsp;on.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The build process was good fun and I am very happy with the final outcome. It&amp;#8217;s been in use for three weeks now and works reliably: It is a great comfort to be able to control the light from all over the world as well as to control it through the physical switch. In particular, the 3D printed mechanical switch mechanism turns out to work very&amp;nbsp;well.&lt;/p&gt;
&lt;p&gt;Last but not least, the following picture shows the lamp in its new&amp;nbsp;habitat:&lt;/p&gt;
&lt;div class="figure"&gt;
&lt;a class="reference external image-reference" href="http://lellep.xyz/blog/images/wooden_IoT_lamp/hr/17_lamp_habitat.jpg"&gt;&lt;img alt="" src="http://lellep.xyz/blog/images/wooden_IoT_lamp/lr/17_lamp_habitat.jpg" style="width: 500px;" /&gt;&lt;/a&gt;
&lt;p class="caption"&gt;View of how I use the lamp in my&amp;nbsp;room.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</content></entry><entry><title>Phone in foreignÂ language</title><link href="http://lellep.xyz/blog/phone-in-foreign-language.html" rel="alternate"></link><published>2019-09-14T10:46:00+02:00</published><updated>2019-09-14T10:46:00+02:00</updated><author><name>Martin Lellep</name></author><id>tag:lellep.xyz,2019-09-14:/blog/phone-in-foreign-language.html</id><summary type="html">&lt;p class="first last"&gt;My experiences with using my phone in Russian for 1&amp;nbsp;year.&lt;/p&gt;
</summary><content type="html">&lt;p&gt;In around August 2018, I switched my phone&amp;#8217;s language from English to Russian. I switched it back to English mid-September of this year&amp;nbsp;(2019).&lt;/p&gt;
&lt;p&gt;The idea of switching my phone to Russian arose from the desire to expose myself to the Russian language more authentically in daily life. As my phone is my daily fellow, using it in Russian suggested&amp;nbsp;itself.&lt;/p&gt;
&lt;p&gt;During a vacation in an Eastern Russians-speaking country in September 2019, I came to the conclusion that this strategy is suboptimal at this point in time. These are the major three reasons why I decided to switch it back, sorted according to their&amp;nbsp;importance:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;My level of Russian is admittedly not high enough to make practical use of this daily authentic&amp;nbsp;exposure.&lt;/li&gt;
&lt;li&gt;Studying Russian at an beginner-ish level, adhering to text books seems to be a more efficient solution. The latter approach appears to be a denser and more explicit learning experience. Despite its lack of authenticity, it is probably more efficient at the beginning of learning a&amp;nbsp;language.&lt;/li&gt;
&lt;li&gt;The phone&amp;#8217;s usability is severely crippled if one does not honestly attempt to learn all the new words one is exposed&amp;nbsp;to.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;I would like to conclude by encouraging you, fellow language learners, to try it out in your target language! It is indeed very authentic and learning through this approach by the mechanism of &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Osmosis"&gt;osmosis&lt;/a&gt; did work for me. I haven&amp;#8217;t learned as many new words as I wanted to but this is solely due to me being not consistent enough and now having a high enough skill level in Russian, yet. In the future, I will certainly set my phone back to Russian&amp;nbsp;again!&lt;/p&gt;
</content></entry><entry><title>3D printed bike lockÂ mount</title><link href="http://lellep.xyz/blog/3d-printed-bike-lock-mount.html" rel="alternate"></link><published>2019-09-01T00:00:00+02:00</published><updated>2019-09-01T00:00:00+02:00</updated><author><name>Martin Lellep</name></author><id>tag:lellep.xyz,2019-09-01:/blog/3d-printed-bike-lock-mount.html</id><summary type="html">&lt;p class="first last"&gt;Over are the days of juggling a bike lock while riding my&amp;nbsp;bike!&lt;/p&gt;
</summary><content type="html">&lt;p&gt;I like my bike and want to protect it from evil thieves. For that, I use an old solid
lock that comes with the downside of being quite bulky to carry while riding my&amp;nbsp;bike.&lt;/p&gt;
&lt;p&gt;Of course, there are solutions to this such as putting it in a backpack or holding it in
my hand while riding. But &amp;#8230; where is the fun with these? In particular, when there is
my 3D printer waiting eagerly for jobs. The following figure shows the frame of my bike
from the side. Clearly, there is space for some 3D printed mounting solution&amp;nbsp;:-).&lt;/p&gt;
&lt;div class="figure"&gt;
&lt;a class="reference external image-reference" href="http://lellep.xyz/blog/images/bike_lock_mount_3d_print/hr/0_picture_of_frame.jpg"&gt;&lt;img alt="" src="http://lellep.xyz/blog/images/bike_lock_mount_3d_print/lr/0_picture_of_frame.jpg" style="width: 500px;" /&gt;&lt;/a&gt;
&lt;p class="caption"&gt;Side view of my bike&amp;#8217;s frame. The red arrow indicates available space for
a 3D printed mounting solution for my bike&amp;nbsp;lock.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;With the idea in mind to 3D print my prospective bike lock mount, this task becomes
a well-defined engineering question. Hence, I model it digitally as a first&amp;nbsp;step.&lt;/p&gt;
&lt;div class="section" id="modeling-the-problem"&gt;
&lt;h2&gt;Modeling the&amp;nbsp;problem&lt;/h2&gt;
&lt;p&gt;My bike&amp;#8217;s frame is modeled in &lt;span class="caps"&gt;CAD&lt;/span&gt; with &lt;em&gt;Autodesk Fusion 360&lt;/em&gt;. Subsequently, the
same is performed for my old&amp;nbsp;lock.&lt;/p&gt;
&lt;p&gt;First, I import the above figure into &lt;a class="reference external" href="https://en.wikipedia.org/wiki/ImageJ"&gt;ImageJ&lt;/a&gt;
to determine the angle between the two major rods accurately. This is shown in the following
figure. Second, the bike lock is measured and drawn in 3D as&amp;nbsp;well.&lt;/p&gt;
&lt;div class="figure"&gt;
&lt;a class="reference external image-reference" href="http://lellep.xyz/blog/images/bike_lock_mount_3d_print/hr/1_measuring_angles.png"&gt;&lt;img alt="" src="http://lellep.xyz/blog/images/bike_lock_mount_3d_print/lr/1_measuring_angles.png" style="width: 500px;" /&gt;&lt;/a&gt;
&lt;p class="caption"&gt;Measuring the geometry of my bike&amp;#8217;s&amp;nbsp;frame.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;After modeling the physical system, the fun of designing the bike lock mount itself
begins. Keeping in mind that this design will be 3D printed, I chose a three-part
approach: two identical parts are used as attachments to the frame and the third part
mounts the lock. Without further explaining the design with bare words, please check out
the video below to see how it works in an animation. The white pieces are 3D printed
and metal screws (not shown) are used to hold all pieces&amp;nbsp;together.&lt;/p&gt;
&lt;div style="margin: 0px auto; text-align: center;"&gt;
    &lt;iframe width="650" height="365" src="https://www.youtube.com/embed/JYmiPLFMNRY" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen&gt;&lt;/iframe&gt;
&lt;/div&gt;
&lt;br/&gt;&lt;p&gt;Additionally, the following figure shows a rendering of the whole setup while being
mounted to the bike&amp;nbsp;frame.&lt;/p&gt;
&lt;div class="figure"&gt;
&lt;a class="reference external image-reference" href="http://lellep.xyz/blog/images/bike_lock_mount_3d_print/hr/2_rendering.png"&gt;&lt;img alt="" src="http://lellep.xyz/blog/images/bike_lock_mount_3d_print/lr/2_rendering.png" style="width: 500px;" /&gt;&lt;/a&gt;
&lt;p class="caption"&gt;Rendering of the designed 3D&amp;nbsp;model.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;This design is printed on my 3D printer in white &lt;span class="caps"&gt;PLA&lt;/span&gt;. It took around 2x 7h plus 1x 9h, accumulating
to 23h of print time. This long print time arises from the somewhat rigid design and
the very slow print speed that I used. Prior to the design shown in the video above, there existed a
previous design that I did not use due to a failed test print which revealed that it was too bulky.
After the 3D printer finished
with my final design, it was carefully sanded and tested for proper fitting. The following shows
the parts layed out on a&amp;nbsp;table.&lt;/p&gt;
&lt;div class="figure"&gt;
&lt;a class="reference external image-reference" href="http://lellep.xyz/blog/images/bike_lock_mount_3d_print/hr/3_parts.jpg"&gt;&lt;img alt="" src="http://lellep.xyz/blog/images/bike_lock_mount_3d_print/lr/3_parts.jpg" style="width: 500px;" /&gt;&lt;/a&gt;
&lt;p class="caption"&gt;All parts that are necessary for the assembly. The white parts were 3D printed and the remaining
items are the metal screws and&amp;nbsp;washers.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Finally, the following two images present a test assembly of the design and verify that not only the
designed parts fit together but also that the lock fits inside. With this, the assembly is ready to be mounted
to the&amp;nbsp;bike.&lt;/p&gt;
&lt;div class="figure"&gt;
&lt;a class="reference external image-reference" href="http://lellep.xyz/blog/images/bike_lock_mount_3d_print/hr/4_half_assembly.jpg"&gt;&lt;img alt="" src="http://lellep.xyz/blog/images/bike_lock_mount_3d_print/lr/4_half_assembly.jpg" style="width: 500px;" /&gt;&lt;/a&gt;
&lt;p class="caption"&gt;Half assembled bike lock mount with inserted metal&amp;nbsp;screws.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="figure"&gt;
&lt;a class="reference external image-reference" href="http://lellep.xyz/blog/images/bike_lock_mount_3d_print/hr/5_test_assembly.jpg"&gt;&lt;img alt="" src="http://lellep.xyz/blog/images/bike_lock_mount_3d_print/lr/5_test_assembly.jpg" style="width: 500px;" /&gt;&lt;/a&gt;
&lt;p class="caption"&gt;Finished test assembly. The lock does fit inside the&amp;nbsp;design.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="mounting-the-3d-print"&gt;
&lt;h2&gt;Mounting the 3D&amp;nbsp;print&lt;/h2&gt;
&lt;p&gt;After cleaning the relevant parts of the bike, the bike lock mount is installed.
First, a rubber band is wrapped around the bike shaft to improve adhesion of
the mount to the bike in azimuthal direction. This can be seen in the following&amp;nbsp;figure.&lt;/p&gt;
&lt;div class="figure"&gt;
&lt;a class="reference external image-reference" href="http://lellep.xyz/blog/images/bike_lock_mount_3d_print/hr/6_rubber.jpg"&gt;&lt;img alt="" src="http://lellep.xyz/blog/images/bike_lock_mount_3d_print/lr/6_rubber.jpg" style="width: 500px;" /&gt;&lt;/a&gt;
&lt;p class="caption"&gt;Rubber band wrapped around the bike shaft to increase adhesion of the 3D&amp;nbsp;print.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Second, the two identical parts are screwed around the shaft in order to, finally, screw the last 3D
printed piece to the two identical parts. The following two figures show these steps in&amp;nbsp;detail.&lt;/p&gt;
&lt;div class="figure"&gt;
&lt;a class="reference external image-reference" href="http://lellep.xyz/blog/images/bike_lock_mount_3d_print/hr/7_bike_assembly_1.jpg"&gt;&lt;img alt="" src="http://lellep.xyz/blog/images/bike_lock_mount_3d_print/lr/7_bike_assembly_1.jpg" style="height: 400px;" /&gt;&lt;/a&gt;
&lt;p class="caption"&gt;The two identical 3D printed pieces are mounted to the&amp;nbsp;frame.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="figure"&gt;
&lt;a class="reference external image-reference" href="http://lellep.xyz/blog/images/bike_lock_mount_3d_print/hr/8_bike_assembly_2.jpg"&gt;&lt;img alt="" src="http://lellep.xyz/blog/images/bike_lock_mount_3d_print/lr/8_bike_assembly_2.jpg" style="width: 500px;" /&gt;&lt;/a&gt;
&lt;p class="caption"&gt;Subsequently, the last piece is mounted to the pieces installed beforehand and the bike lock
is&amp;nbsp;inserted.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;With this, the build is finished and my bike lock mount is safetly mounted to the bike.
Finally, no more dangling around of the&amp;nbsp;lock!&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="conclusion"&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Here, I model a part of my bike in &lt;span class="caps"&gt;CAD&lt;/span&gt; and 3D print a plastics mounting assembly for my bike lock.
The assembly has been in use for one week now and everything continues to work&amp;nbsp;great!&lt;/p&gt;
&lt;p&gt;A few lessons have been learned along the&amp;nbsp;way:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;&lt;span class="caps"&gt;CAD&lt;/span&gt; modeling for such pieces is incredibly useful. One can avoid improper prototypes
by creating good models, e.g. ensuring that all moving parts will behave as&amp;nbsp;desired.&lt;/li&gt;
&lt;li&gt;Model as much as possible. I forgot to model a minute section of the bike lock which
later required heavy manual post&amp;nbsp;processing.&lt;/li&gt;
&lt;li&gt;There is no engineering without ideas on how to improve the part. I do not plan to
3D print another version of this design but in case I had to, the following two
improvements would be integrated: (1) A hole inside the housing of the bike lock mount
body in order to drain water and (2) a design that is a little bit less massive. The
latter comes from the fact that I tend to design my functional 3D prints too massive
in their first iteration because I underestimate the strength of 3D printed &lt;span class="caps"&gt;PLA&lt;/span&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Don&amp;#8217;t hesitate to contact me via email if you have any questions that remain, I would be very happy
to assist you in a similar process or give extra information about my own experiences. I don&amp;#8217;t provide the model
files of the 3D print here because they are very specific to my particular bike and therefore probably
useless for anybody else. Nevertheless, drop me an email if you would like to get the &lt;span class="caps"&gt;STL&lt;/span&gt; files of
my&amp;nbsp;model.&lt;/p&gt;
&lt;p&gt;Last but not least, the obligatory evidence of the bike lock mount in wildlife - as found
at places that might be familiar to people from&amp;nbsp;Marburg.&lt;/p&gt;
&lt;div class="figure"&gt;
&lt;a class="reference external image-reference" href="http://lellep.xyz/blog/images/bike_lock_mount_3d_print/hr/9_evidence_1.jpg"&gt;&lt;img alt="" src="http://lellep.xyz/blog/images/bike_lock_mount_3d_print/lr/9_evidence_1.jpg" style="width: 400px;" /&gt;&lt;/a&gt;
&lt;p class="caption"&gt;The first&amp;nbsp;evidence.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="figure"&gt;
&lt;a class="reference external image-reference" href="http://lellep.xyz/blog/images/bike_lock_mount_3d_print/hr/10_evidence_2.jpg"&gt;&lt;img alt="" src="http://lellep.xyz/blog/images/bike_lock_mount_3d_print/lr/10_evidence_2.jpg" style="width: 400px;" /&gt;&lt;/a&gt;
&lt;p class="caption"&gt;The second&amp;nbsp;evidence.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</content></entry><entry><title>Exporting Anki statisticsÂ manually</title><link href="http://lellep.xyz/blog/exporting-anki-statistics-manually.html" rel="alternate"></link><published>2018-09-29T20:14:00+02:00</published><updated>2018-09-29T20:14:00+02:00</updated><author><name>Martin Lellep</name></author><id>tag:lellep.xyz,2018-09-29:/blog/exporting-anki-statistics-manually.html</id><summary type="html">&lt;p class="first last"&gt;A description of how to export Anki statistics by directly hacking the Anki desktop&amp;nbsp;client.&lt;/p&gt;
</summary><content type="html">&lt;p&gt;In order to document what I was able to achieve while &lt;a class="reference external" href="{filename}/ignored/Qualitative/learning_Italian_for_30_days.rst"&gt;learning Italian for one month&lt;/a&gt;, I wanted to be able to export my Anki statistics to a data format that could be processed and plotted manually. It turns out that there is no feature in the Anki desktop client that enables the easy export of the computed statistics data that is shown on the statistics&amp;nbsp;page.&lt;/p&gt;
&lt;p&gt;However, I found a hack-ish workaround by tweaking the original Anki code that computes the statistics in order to export the data myself. This article is a quick explanation of how to export the statistics that is generated by&amp;nbsp;Anki.&lt;/p&gt;
&lt;p&gt;Here we&amp;nbsp;go:&lt;/p&gt;
&lt;ol class="arabic"&gt;
&lt;li&gt;&lt;p class="first"&gt;Find the Anki installation by typing &lt;tt class="docutils literal"&gt;whereis anki&lt;/tt&gt; in your Linux terminal. My output&amp;nbsp;is:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
$ whereis anki
anki: /usr/bin/anki /usr/share/anki /usr/share/man/man1/anki.1.gz
&lt;/pre&gt;
&lt;p&gt;Checking these paths reveals that &lt;tt class="docutils literal"&gt;/usr/share/anki&lt;/tt&gt; is the path that contains the source files of the Anki desktop client. These files are written in Python. Therefore, it is easy to modify&amp;nbsp;them.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Within &lt;tt class="docutils literal"&gt;/usr/share/anki&lt;/tt&gt;, the file &lt;tt class="docutils literal"&gt;/usr/share/anki/anki/stats.py&lt;/tt&gt; contains all the code that computes the statistics and outputs the data to the corresponding window of the Anki desktop&amp;nbsp;client.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;The code in &lt;tt class="docutils literal"&gt;stats.py&lt;/tt&gt; is self-explanatory and can be modified to one&amp;#8217;s liking. Let me state one example here: The method &lt;tt class="docutils literal"&gt;dueGraph()&lt;/tt&gt; is modified to export the statistics data that it computes anyway. It should be denoted at that point that Anki informs you about errors if erroneous code has been added to any function - that makes debugging your added code quite comfortable. The code is changed as&amp;nbsp;follows:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
# Original version
def dueGraph(self):
    ...
    txt += self._dueInfo(tot, len(totd)*chunk)
    return txt

# Hacked version
def dueGraph(self):
    ...
    txt += self._dueInfo(tot, len(totd)*chunk)
    # &amp;lt;&amp;lt; Start of new code
    import os
    with open(os.path.join('/home/&amp;lt;user&amp;gt;', 'dueGraph.dat'), 'a') as f:
        f.write(json.dumps(data, indent=4))
    # End of new code &amp;gt;&amp;gt;
    return txt
&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;The additional code block creates a file &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;/home/&amp;lt;user&amp;gt;/dueGraph.dat&lt;/span&gt;&lt;/tt&gt; where &lt;tt class="docutils literal"&gt;&amp;lt;user&amp;gt;&lt;/tt&gt; must be replaced by your username. This file contains the data that is used to generate the plot called &amp;#8220;Forecast&amp;#8221; in the statistics&amp;nbsp;window.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;The original plot called &amp;#8220;Forecast&amp;#8221; is shown&amp;nbsp;below.&lt;/p&gt;
&lt;blockquote&gt;
&lt;div class="figure"&gt;
&lt;a class="reference external image-reference" href="http://lellep.xyz/blog/images/export_Anki_statistics_manually/forecast_default_plot.png"&gt;&lt;img alt="" src="http://lellep.xyz/blog/images/export_Anki_statistics_manually/forecast_default_plot.png" style="width: 600px;" /&gt;&lt;/a&gt;
&lt;p class="caption"&gt;The original figure &amp;#8220;Forecast&amp;#8221; from the stats report generated by the Anki desktop&amp;nbsp;client.&lt;/p&gt;
&lt;/div&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;The data that is written to &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;/home/&amp;lt;user&amp;gt;/dueGraph.dat&lt;/span&gt;&lt;/tt&gt; can be used easily to generate a plot that is to your liking based on the underlying data. That is shown in the following figure. This figure has been generated with a &lt;a class="reference external" href="http://lellep.xyz/blog/plot_dueGraph.py"&gt;simple Python&lt;/a&gt; script using matplotlib and &lt;a class="reference external" href="http://lellep.xyz/blog/dueGraph.dat"&gt;the exported data of my Anki deck&lt;/a&gt;.&lt;/p&gt;
&lt;blockquote&gt;
&lt;div class="figure"&gt;
&lt;a class="reference external image-reference" href="http://lellep.xyz/blog/images/export_Anki_statistics_manually/forecast_custom_plot.png"&gt;&lt;img alt="" src="http://lellep.xyz/blog/images/export_Anki_statistics_manually/forecast_custom_plot.png" style="width: 600px;" /&gt;&lt;/a&gt;
&lt;p class="caption"&gt;The underlying data is used to generate a custom&amp;nbsp;figure.&lt;/p&gt;
&lt;/div&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;We are&amp;nbsp;done.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Concluding, it is possible to adapt the original Anki source code to export the statistics data manually, which, ultimately, enables one to create custom plots around that data. While the above procedure shows how already computed data is exported, own statistics based on the raw data in the Anki database could be computed and exported as well. However, attention must be brought to the fact that the plotted data of the above two figures appears &lt;strong&gt;not&lt;/strong&gt; to be the same. I was not able to spot any mistakes from my side or apparent code passages that modify the data after I save it manually in the Anki source&amp;nbsp;code.&lt;/p&gt;
&lt;p&gt;Finally, this article shows that exporting the data is a straightforward process but caution is advised when using the data without any prior&amp;nbsp;inspection.&lt;/p&gt;
&lt;p&gt;Kudos go to Leonard Salewski for his valuable tip to study Anki plugins in order to understand the inner workings of Anki, which led to this hack of the &lt;tt class="docutils literal"&gt;stats.py&lt;/tt&gt; file, and also for general discussions about Anki to enhance the personal learning&amp;nbsp;process.&lt;/p&gt;
</content></entry><entry><title>Learning Italian for 30Â days</title><link href="http://lellep.xyz/blog/learning-italian-for-30-days.html" rel="alternate"></link><published>2018-09-17T23:00:00+02:00</published><updated>2018-09-17T23:00:00+02:00</updated><author><name>Martin Lellep</name></author><id>tag:lellep.xyz,2018-09-17:/blog/learning-italian-for-30-days.html</id><summary type="html">&lt;p class="first last"&gt;Results of the experiment to learn Italian autodidactically for one&amp;nbsp;month.&lt;/p&gt;
</summary><content type="html">&lt;div class="section" id="the-settings"&gt;
&lt;h2&gt;The&amp;nbsp;settings&lt;/h2&gt;
&lt;p&gt;In the beginning of the year, I have decided to meet a few good friends in Italy this September. Having had no prior experience with the Italian language except for hearing conversations of others, I decided to start to learn Italian autodidactically from scratch approximately one month prior to my trip to Italy. Simply as an experiment about what is feasible in such a short amount of&amp;nbsp;time.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="my-stategy"&gt;
&lt;h2&gt;My&amp;nbsp;stategy&lt;/h2&gt;
&lt;p&gt;Since I have had good experiences with Duolingo for freshing up some rusty language skills as well as starting a completely new language, I decided to use the Duolingo app on my phone during the time of the experiment. Since I was working full time professionally, I limited the time spent on Duolingo to 5 minutes per&amp;nbsp;day.&lt;/p&gt;
&lt;p&gt;Different from how I used Duolingo earlier, I decided to accompany the Duolingo activity with daily review activities on Anki. I constrained myself to 5 minutes of Duolingo time because I wanted to put extra emphasis on Anki: Whatever I learned through Duolingo, I planned to type in Anki to repeat the Duolingo content even further. I knew that the time spent on Anki grows roughly linearly with time in the beginning of using Anki for a new subject so that utilising only 5 minutes per day for Duolingo plus the time spent on Anki to repeat the Duolingo content seemed realistic to me. I configured Anki to introduce 3 new cards to me per&amp;nbsp;day.&lt;/p&gt;
&lt;p&gt;I wanted to focus on Anki because I&amp;#8217;ve had phenomenal experiences with Anki regarding other subjects. I use it daily for reviewing flash cards that deal with Physics, computer science and language knowledge. My experiences show that whatever I type into Anki burns into my mind, justifying spending more time on Anki than on Duolingo for this&amp;nbsp;experiment.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="the-leading-questions"&gt;
&lt;h2&gt;The leading&amp;nbsp;questions&lt;/h2&gt;
&lt;p&gt;The purpose for conducting this experiment is manyfold. The following questions were of interest to me, in increasing generalising&amp;nbsp;order:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;How much of Italian is it possible to learn in one&amp;nbsp;month?&lt;/li&gt;
&lt;li&gt;How well do Duolingo and Anki play together? What are the timescales one is making progress for each of&amp;nbsp;them?&lt;/li&gt;
&lt;li&gt;How well does the strategy work out for a language? I conjecture that the answer to that question generalises to other languages as&amp;nbsp;well.&lt;/li&gt;
&lt;li&gt;How realistic is such a strategy during working full&amp;nbsp;time?&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div class="section" id="the-results"&gt;
&lt;h2&gt;The&amp;nbsp;results&lt;/h2&gt;
&lt;p&gt;I conducted the experiment successfully without any days left out. Below, the Duolingo activity overview after half of the experiment can be&amp;nbsp;seen.&lt;/p&gt;
&lt;div class="figure align-center"&gt;
&lt;a class="reference external image-reference" href="http://lellep.xyz/blog/images/learning_Italian_for_30_days/duolingo_scores.png"&gt;&lt;img alt="" src="http://lellep.xyz/blog/images/learning_Italian_for_30_days/duolingo_scores.png" style="width: 400px;" /&gt;&lt;/a&gt;
&lt;p class="caption"&gt;The Duolingo activity overview taken from the weekly emails one gets when using&amp;nbsp;Duolingo.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;The following figure - taken from the Anki statistics feature - shows my Anki statistics after the whole experiment and reveals how many new words I learned, how much time I spent and how many flash cards I have reviewed, amongst&amp;nbsp;others.&lt;/p&gt;
&lt;div class="figure align-center"&gt;
&lt;a class="reference external image-reference" href="http://lellep.xyz/blog/images/learning_Italian_for_30_days/statistics_composite.png"&gt;&lt;img alt="" src="http://lellep.xyz/blog/images/learning_Italian_for_30_days/statistics_composite.png" style="width: 600px;" /&gt;&lt;/a&gt;
&lt;p class="caption"&gt;My Anki statistics of learning Italian for one month. Each letter corresponds to one evaluation and the letters (i) and (ii)
correspond to the monthly and yearly statistics, respectively. The latter is shown since I learned Italian for a few days more than one&amp;nbsp;month.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;The most apparent results are the following ones. I&amp;nbsp;&amp;#8230;&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&amp;#8230; spent &lt;strong&gt;1 hour&lt;/strong&gt; of reviewing Anki flashcards with an average of &lt;strong&gt;1.4 minutes per day&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;&amp;#8230; reviewed &lt;strong&gt;708 flashcards&lt;/strong&gt; with an average of &lt;strong&gt;14.4 flashcards per day&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;&amp;#8230; spent an average of &lt;strong&gt;5.9s per cards&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;&amp;#8230; added &lt;strong&gt;162 flashcards&lt;/strong&gt; altogether. After the whole month, &lt;strong&gt;26 flashcards remained unseen&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The latter aspect reveals that Anki operates on a slower timescale than Duolingo does since I used solely Duolingo content for my Anki studies. Thus, when using Duolingo as an input for new content, the additional learning process with Anki is delayed. However, whatever is entered into Anki really burns into my mind. For me, it felt that if I progressed with Duolingo as fast as possible, the progress speed with the content from Duolingo would be slightly too fast for me. With that knowledge, I can adjust any future experiments with that fact in&amp;nbsp;mind.&lt;/p&gt;
&lt;p&gt;Another interesting fact was that my very small experience of hearing Italian conversations really helped in studying Italian. It seemed to me like I knew the basic phonetics and potential ways to pronouce the words that I learned. This finding emphasises the advice that many experienced language learners give: Expose yourself to the spoken language as much as possible while learning the respective&amp;nbsp;language.&lt;/p&gt;
&lt;p&gt;Along the same lines, learning a language in conjuntion with visiting the corresponding country once in a while makes sense. Not only does it boost one&amp;#8217;s motivation but it also familarises with the sound of the language. Last but not least, the native speakers you meet make up a large portion of the fun of learning a new&amp;nbsp;language!&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="future-directions"&gt;
&lt;h2&gt;Future&amp;nbsp;directions&lt;/h2&gt;
&lt;p&gt;The most apparent extension to this experiment is to do it for a longer time, e.g. for one summer or one year. Since I would like to refresh another language first and want to try to use Anki for other types of knowledge at this point in time, I am not able to continue this experiment with Italian for now. However, I will use it with the afore mentioned other&amp;nbsp;language.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="conclusion"&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Let me present to you what my conclusions&amp;nbsp;are:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;One does learn quite a bit in such a short amount of time, even with limited time spent. However, since I was able to check my progress right in Italy, I have to admit that there is a lot more to be learned before a language is usable after an experiment like this. Anyway, it gave some good intro to that language and I&amp;#8217;d do it again for either the same or other&amp;nbsp;languages.&lt;/li&gt;
&lt;li&gt;The experiment showed to me that Anki alone is not the best. By that, my experiment confirmed &lt;a class="reference external" href="https://apps.ankiweb.net/docs/manual.html#downloading-shared-decks"&gt;Anki&amp;#8217;s recommendation&lt;/a&gt; of &lt;strong&gt;not&lt;/strong&gt; to use Anki for stand-alone knowledge but to use it in conjuntion with other types of classes or&amp;nbsp;tutorials.&lt;/li&gt;
&lt;li&gt;With the former, it is clear that also applying the gained knowledge is advisable. For instance with an additional language course, a tandem buddy, by writing texts or&amp;nbsp;traveling.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;No writing about Italy without a pretty&amp;nbsp;picture!&lt;/p&gt;
&lt;div class="figure align-center"&gt;
&lt;a class="reference external image-reference" href="http://lellep.xyz/blog/images/learning_Italian_for_30_days/Napels_beach.jpg"&gt;&lt;img alt="" src="http://lellep.xyz/blog/images/learning_Italian_for_30_days/Napels_beach.jpg" style="width: 600px;" /&gt;&lt;/a&gt;
&lt;p class="caption"&gt;The cozy beach of Napels with the volcano &lt;em&gt;Mount Vesuvius&lt;/em&gt; in the&amp;nbsp;background.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</content></entry><entry><title>Turbulence simulation data inÂ real-life</title><link href="http://lellep.xyz/blog/turbulence-simulation-data-in-real-life.html" rel="alternate"></link><published>2017-12-19T00:00:00+01:00</published><updated>2017-12-19T00:00:00+01:00</updated><author><name>Martin Lellep</name></author><id>tag:lellep.xyz,2017-12-19:/blog/turbulence-simulation-data-in-real-life.html</id><summary type="html">&lt;p class="first last"&gt;3D print and resin cast of a turbulent flow from 3D simulation&amp;nbsp;data.&lt;/p&gt;
</summary><content type="html">&lt;p&gt;Amongst others, I developed a code for simulating Newtonian fluids such as water
during my Master studies. Choosing proper settings, one can easily generate large
amounts of 3D data that resembles a turbulent flow in a&amp;nbsp;box.&lt;/p&gt;
&lt;p&gt;A snapshot of this data was captured and 3D printed. From that, a silicone mould was
made and used to cast a resin version of the simulation&amp;nbsp;data.&lt;/p&gt;
&lt;p&gt;Thus, I am able to hold my abstract experiments from my studies in Theoretical
Physics in my own hands. It took a long way from performing the simulation on a
powerful super computer to creating a real-life silicone mould with which the data
can be&amp;nbsp;casted.&lt;/p&gt;
&lt;p&gt;The steps that I performed are the following&amp;nbsp;ones:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;Generate the turbulent data in a channel flow geometry. The boundary conditions
are periodic in spanwise and streamwise directions. The wall-normal direction
uses free-slip boundary&amp;nbsp;conditions.&lt;/li&gt;
&lt;li&gt;The data is exported to the &lt;span class="caps"&gt;VTR&lt;/span&gt; format which is read by ParaView. From there,
it is exported as &lt;span class="caps"&gt;STL&lt;/span&gt;. ParaView is used to find a nice iso surface in the
time&amp;nbsp;series.&lt;/li&gt;
&lt;li&gt;The raw simulation data is post-processed in Blender to generate a file
that can be 3D&amp;nbsp;printed.&lt;/li&gt;
&lt;li&gt;The post-processed &lt;span class="caps"&gt;STL&lt;/span&gt; is 3D&amp;nbsp;printed.&lt;/li&gt;
&lt;li&gt;The 3D print is sanded and subsequently coated with a fill primer to hide the
3D print specific layer&amp;nbsp;structure.&lt;/li&gt;
&lt;li&gt;A silicone mould is made from the 3D print which is finally used for the resin&amp;nbsp;cast.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The following video visualizes the simulation from which the 3D printed data is taken.
The flow in the simulation box is color
coded where red values are large positive values in the flow  direction and blue values are large negative
values in the flow direction. The flow direction is the x coordinate. The gray surface at t=0 is the one
that is 3D printed and resin casted here. The video shows the turbulent evolution of that surface in&amp;nbsp;time.&lt;/p&gt;
&lt;div class="figure"&gt;
&lt;a class="reference external image-reference" href="http://lellep.xyz/blog/videos/turbulentDataCast/turbulence_isosurfaces.mp4"&gt;&lt;img alt="" src="http://lellep.xyz/blog/images/turbulentDataCast/turbulence_isosurfaces_frontPic.png" style="width: 600px;" /&gt;&lt;/a&gt;
&lt;p class="caption"&gt;The simulation data that has been used for the&amp;nbsp;cast.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;The video is a mp4 file and can either be downloaded or viewed directly in the&amp;nbsp;browser.&lt;/p&gt;
&lt;div class="section" id="the-outcome"&gt;
&lt;h2&gt;The&amp;nbsp;outcome&lt;/h2&gt;
&lt;p&gt;Below, the result of the cast is shown: It is the transparent piece which took
two days to cure inside the silicone&amp;nbsp;mould.&lt;/p&gt;
&lt;div class="figure"&gt;
&lt;img alt="" src="http://lellep.xyz/blog/images/turbulentDataCast/lr/0_3d_prints.jpg" style="width: 400px;" /&gt;
&lt;p class="caption"&gt;3D prints in two sizes, colors and&amp;nbsp;resolutions.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="figure"&gt;
&lt;img alt="" src="http://lellep.xyz/blog/images/turbulentDataCast/lr/1_mould_box.jpg" style="width: 400px;" /&gt;
&lt;p class="caption"&gt;3D print with white fill primer inside its silicone moulding&amp;nbsp;box.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="figure"&gt;
&lt;img alt="" src="http://lellep.xyz/blog/images/turbulentDataCast/lr/2_silicone_mould.jpg" style="width: 400px;" /&gt;
&lt;p class="caption"&gt;Silicone&amp;nbsp;mould.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="figure"&gt;
&lt;img alt="" src="http://lellep.xyz/blog/images/turbulentDataCast/lr/3_resin_cast.jpg" style="width: 400px;" /&gt;
&lt;p class="caption"&gt;Resin cast and its&amp;nbsp;template.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="the-details"&gt;
&lt;h2&gt;The&amp;nbsp;details&lt;/h2&gt;
&lt;p&gt;The data is acquired by running the simulation that I wrote for a sufficiently
long time in the incompressible Navier-Stokes equations&amp;#8217; turbulent regime at
Re=400. My simulation is based on a pseudo-spectral algorithm so that one
can reconstruct the full velocity fields from the spectral expansion coefficients
at arbitrary spatial resolutions. The fields are reconstructed and
saved as &lt;span class="caps"&gt;VTR&lt;/span&gt; files (using &lt;a class="reference external" href="https://bitbucket.org/pauloh/pyevtk"&gt;PyEVTK&lt;/a&gt;).
These can be opened in &lt;a class="reference external" href="https://www.paraview.org/"&gt;ParaView&lt;/a&gt; to study how
the fields evolve over time. After deciding upon one flow field and
one of its iso surfaces, the spectral coefficients are used to generate a very
high-resolution spatial field. This data is saved as a &lt;span class="caps"&gt;STL&lt;/span&gt;&amp;nbsp;file.&lt;/p&gt;
&lt;p&gt;The &lt;span class="caps"&gt;STL&lt;/span&gt; file is post-processed in Blender: The 2D iso surface is extruded
downwards to obtain a true 3D structure that can be 3D printed. Furthermore,
small artifacts or structures that are hard to 3D print are&amp;nbsp;removed.&lt;/p&gt;
&lt;p&gt;The model is 3D printed in black &lt;span class="caps"&gt;PLA&lt;/span&gt;. I tested multiple sizes and multiple vertical resolutions
on an UltiMaker 3. After holding all the 3D prints in my hand I decided to pick
the highest vertical resolution of 0.1mm and a size of 9mm x 6mm x 3mm. This
model is sanded down and white fill primer is applied to hide the vertical layers. It turns out
that this last step reduces the visible vertical layers very well.
That procedure might be an alternative to using an acetone bath for &lt;span class="caps"&gt;ABS&lt;/span&gt; in
case &lt;span class="caps"&gt;ABS&lt;/span&gt; cannot be used but a smooth surface is necessary,&amp;nbsp;though.&lt;/p&gt;
&lt;p&gt;A silicone mould is made in a small paper box. Using release spray is recommended
to avoid the destruction of the silicone mould while removing the 3D print. Spending some
time to prepare the 3D print is suggested to polish its look and feel because
the silicone will capture all its details for all the following resin casts to&amp;nbsp;create.&lt;/p&gt;
&lt;p&gt;This silicone mould is finally used for a resin cast. One can use the silione
mould many times. The casting should be done in a well ventilated room, believe&amp;nbsp;me!&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="acknowledgements"&gt;
&lt;h2&gt;Acknowledgements&lt;/h2&gt;
&lt;p&gt;Cheers to the &lt;a class="reference external" href="http://www.ucreatestudio.is.ed.ac.uk/"&gt;uCreate Studio from the University of Edinburgh&lt;/a&gt;  which enabled me to
test multiple prototypes of the 3D print in various sizes and resolutions.
Thanks to their Mike Boyd for ideas on how to realize this project.
This place is truely exceptional and an amazing opportunity for students
to learn anything! I believe the uCreate Studio is a concept that needs to be copied
from universities across the&amp;nbsp;world.&lt;/p&gt;
&lt;/div&gt;
</content></entry><entry><title>Greasing the groove: Push ups -Â Results</title><link href="http://lellep.xyz/blog/greasing-the-groove-push-ups-results.html" rel="alternate"></link><published>2017-05-29T23:00:00+02:00</published><updated>2017-05-29T23:00:00+02:00</updated><author><name>Martin Lellep</name></author><id>tag:lellep.xyz,2017-05-29:/blog/greasing-the-groove-push-ups-results.html</id><summary type="html">&lt;p class="first last"&gt;Results of 120 push ups for 30&amp;nbsp;days.&lt;/p&gt;
</summary><content type="html">&lt;p&gt;I did 120 push ups, 6 times 20 repetitions spread arbitrarily over the day, for 30 days
starting the 04/24/2017. The last of these workouts has been done the 23rd of May 2017 without
skipping any repetition during the 30 days. After all, I performed 3600 push&amp;nbsp;ups.&lt;/p&gt;
&lt;p&gt;Today, the 29th of May 2017, I measured my maximal number of push ups anew. Initially, I performed
42 with 20 warming up&amp;nbsp;repetitions.&lt;/p&gt;
&lt;p&gt;This time without warming up repetitions, I performed 70 push ups. This is a performance I am
happy&amp;nbsp;about.&lt;/p&gt;
&lt;div class="section" id="experiences"&gt;
&lt;h2&gt;Experiences&lt;/h2&gt;
&lt;p&gt;After approximately 15 days into the challenge, I felt that my handstand and overall
shoulder strength increased. Exercices such as holding a frog position without leaning on my knees
became more accessible and the initial phase of a straddle press felt like I could make future progress
with. In comparison to my pull up challenge of 50 pull ups a day for 30 days in the winter 2015/2016,
this challenge has not had an as big impact on my daily life in terms of soreness and time consumption.
However, also the performance increase hasn&amp;#8217;t been as dramatic. Generally, one should make sure that the
excercise performed in such a challenge is not too difficult as the body will struggle even with the
simplest excercises when repeated that often. While I underestimated that for the past
pull up challenge, I did take this into account for the just finished push up challenge. Getting the 6
sets done over a day was relatively easy so that one could think of performing more than 6 sets. I
did the repetitions exclusively on parallets which (a) protected my wrists and (b) increased the range of
motion. My wrists never made any problems and, amazingly, I got used to the increased range of motion
so that regular flat-hand push ups feel easy now. While the wrists were fine throughout the challenge,
my shoulder felt irritated sometimes. However, never to the degree of pain but mostly only&amp;nbsp;cracking.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="outlook"&gt;
&lt;h2&gt;Outlook&lt;/h2&gt;
&lt;p&gt;Various future challanges came to my&amp;nbsp;mind:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;3x 50 push up repetitions a day: For increasing the maximal number. 20 repetitions were too easy
after some&amp;nbsp;time.&lt;/li&gt;
&lt;li&gt;L sit to tucked press (explained in terms of the frog position above). I might train these excercises
separately at first to build up enough strength for the&amp;nbsp;challenge.&lt;/li&gt;
&lt;li&gt;Frog stand on&amp;nbsp;parallets.&lt;/li&gt;
&lt;li&gt;Stretching routine each&amp;nbsp;day.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The stretching routine seems the most appealing for me now as it is more passive after such an active&amp;nbsp;challenge.&lt;/p&gt;
&lt;/div&gt;
</content></entry><entry><title>Greasing the groove: PushÂ ups</title><link href="http://lellep.xyz/blog/greasing-the-groove-push-ups.html" rel="alternate"></link><published>2017-04-23T18:00:00+02:00</published><updated>2017-04-23T18:00:00+02:00</updated><author><name>Martin Lellep</name></author><id>tag:lellep.xyz,2017-04-23:/blog/greasing-the-groove-push-ups.html</id><summary type="html">&lt;p class="first last"&gt;Application of &amp;#8220;greasing the groove&amp;#8221; training method to push&amp;nbsp;ups.&lt;/p&gt;
</summary><content type="html">&lt;p&gt;I apply the training method &amp;#8220;Greasing the groove&amp;#8221; &lt;a class="footnote-reference" href="#gtg" id="id1"&gt;[1]&lt;/a&gt; to my push up performance.
My interpretation of this method&amp;nbsp;is:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Do not train the excercise to&amp;nbsp;fatigue.&lt;/li&gt;
&lt;li&gt;Train the excercise very&amp;nbsp;frequently.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The application to push ups means in this case for&amp;nbsp;me:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;Determine the maximal performance. Performance is measured as number of
proper-form push ups. To relax my wrists and increase the range of motion, I use my &lt;span class="caps"&gt;DIY&lt;/span&gt;
parallets or knuckles if no parallets are available. &lt;strong&gt;Result&lt;/strong&gt;:
42 push ups after a warm up set of 20&amp;nbsp;repetitions.&lt;/li&gt;
&lt;li&gt;Perform half of the maximal performance - 20 in my case at the time being -
six times each day for 30 days. I determined the set number of six by available
time each day, integration in my other physical training and exhaustion. The number of
sets should be distributed equally over the day and are possibly integrated in other training
occasions. The equal distribution includes working times and time at&amp;nbsp;home.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The purposes of this study&amp;nbsp;are:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Increase push up performance. While push ups are an essential excercise, I found
them surprisingly exhausting. I had very good experience with 50 (ring) pull ups
each day for 30 days for my pull up performance in winter&amp;nbsp;2015/2016.&lt;/li&gt;
&lt;li&gt;Increase overall push performance. This will help for more complex composite movements
that I am weak&amp;nbsp;in.&lt;/li&gt;
&lt;li&gt;Develop a better push up&amp;nbsp;form.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The start date is tomorrow, &lt;strong&gt;04/24/2017&lt;/strong&gt;!&lt;/p&gt;
&lt;blockquote&gt;
&amp;#8220;We are what we repeatedly do. Excellence, then, is not an act, but a habit.&amp;#8221; (Will Durant)&lt;/blockquote&gt;
&lt;hr class="docutils" /&gt;
&lt;table class="docutils footnote" frame="void" id="gtg" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id1"&gt;[1]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;Further reading can be found here: &lt;a class="reference external" href="http://www.100pushups.com/greasing-the-groove/"&gt;http://www.100pushups.com/greasing-the-groove/&lt;/a&gt;.
No guarantee on correctness but a good read.&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
</content></entry></feed>