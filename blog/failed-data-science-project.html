<!doctype html>
<html lang="en">

<head>
  <!-- Required meta tags -->
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <title>  Data Science Project Failing After 1,600¬†Days | Blog
</title>
  <link rel="canonical" href="https://lellep.xyz/blog/failed-data-science-project.html">

    <link rel="apple-touch-icon" href="https://lellep.xyz/blog/apple-touch-icon.png" sizes="180x180">
    <link rel="icon" type="image/png" href="https://lellep.xyz/blog/favicon-32x32.png" sizes="32x32">
    <link rel="icon" type="image/png" href="https://lellep.xyz/blog/favicon-16x16.png" sizes="16x16">
    <link rel="manifest" href="https://lellep.xyz/blog/manifest.json">
    <meta name="theme-color" content="#333333">

  <link rel="stylesheet" href="https://lellep.xyz/blog/theme/css/bootstrap.min.css">
  <link rel="stylesheet" href="https://lellep.xyz/blog/theme/css/fontawesome.min.css">
  <link rel="stylesheet" href="https://lellep.xyz/blog/theme/css/pygments/default.min.css">
  <link rel="stylesheet" href="https://lellep.xyz/blog/theme/css/theme.css">

  <link rel="alternate" type="application/atom+xml" title="Full Atom Feed"
        href="https://lellep.xyz/blog/feeds/all.atom.xml">
  <link rel="alternate" type="application/atom+xml" title="Categories Atom Feed"
        href="https://lellep.xyz/blog/feeds/data.atom.xml">  
  <meta name="description" content="I dedicated over 1,600 days to a data science project, only to see it fail. In this article, I share a new checklist I developed to help prevent similar setbacks in the¬†future.">
  <script>
  // ===
  // Taken from: https://developers.google.com/analytics/devguides/collection/gajs/?hl=de&authuser=0#disable
  // ===

  // Set to the same value as the web property used on the site
  var gaProperty = 'UA-142575904-2';

  // Disable tracking if the opt-out cookie exists.
  var disableStr = 'ga-disable-' + gaProperty;
  if (document.cookie.indexOf(disableStr + '=true') > -1) {
    window[disableStr] = true;
  }

  // Opt-out function
  function gaOptout() {
    document.cookie = disableStr + '=true; expires=Thu, 31 Dec 2099 23:59:59 UTC; path=/';
    window[disableStr] = true;
  }
  </script>
  <script>
    (function(i, s, o, g, r, a, m) {
      i['GoogleAnalyticsObject'] = r;
      i[r] = i[r] || function() {
        (i[r].q = i[r].q || []).push(arguments)
      }, i[r].l = 1 * new Date();
      a = s.createElement(o);
      a.async = 1;
      a.src = g;
      m = s.getElementsByTagName(o)[0];
      m.parentNode.insertBefore(a, m)
    })(window, document, 'script', 'https://www.google-analytics.com/analytics.js', 'ga');
    ga('create', 'UA-142575904-2', 'auto');
    ga('send', 'pageview');
  </script>


  <script data-goatcounter="https://lellep.goatcounter.com/count"
        async src="//gc.zgo.at/count.js"></script>
  <!-- Mathjax -->
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script></head>

<body>
  <header class="header">
    <div class="container">
<div class="row">
    <div class="col-sm-4">
      <a href="https://lellep.xyz/blog/">
        <img class="img-fluid rounded" src=https://lellep.xyz/blog/images/logo.svg alt="Blog">
      </a>
    </div>
  <div class="col-sm-8">
    <h1 class="title"><a href="https://lellep.xyz/blog/">Blog</a></h1>
      <p class="text-muted">by Martin Lellep</p>
      <ul class="list-inline">
          <li class="list-inline-item"><a href="http://lellep.xyz/" target="_blank">‚óÑ back to my main website</a></li>
              <li class="list-inline-item text-muted">|</li>
            <li class="list-inline-item"><a href="https://lellep.xyz/blog/pages/about.html">About</a></li>
            <li class=" list-inline-item text-muted">|</li>
          <li class="list-inline-item"><a class="fab fa-bitbucket" href="https://bitbucket.org/Mc_M/" target="_blank"></a></li>
      </ul>
  </div>
</div>    </div>
  </header>

  <div class="main">
    <div class="container">
      <h1>  Data Science Project Failing After 1,600&nbsp;Days
</h1>
      <hr>
  <article class="article">
    <header>
      <ul class="list-inline">
        <li class="list-inline-item text-muted" title="2024-12-01T00:00:00+01:00">
          <i class="fas fa-clock"></i>
          Sun 01 December 2024
        </li>
        <li class="list-inline-item">
          <i class="fas fa-folder-open"></i>
          <a href="https://lellep.xyz/blog/category/data.html">data</a>
        </li>
          <li class="list-inline-item">
            <i class="fas fa-tag"></i>
              <a href="https://lellep.xyz/blog/tag/data.html">#data</a>,               <a href="https://lellep.xyz/blog/tag/project.html">#project</a>,               <a href="https://lellep.xyz/blog/tag/machine-learning.html">#machine-learning</a>,               <a href="https://lellep.xyz/blog/tag/failures.html">#failures</a>          </li>
      </ul>
    </header>
    <div class="content">
      <p>üí° This blog post reached <a class="reference external" href="https://news.ycombinator.com/front?day=2024-12-08">the Front Page of Hacker News on December 8, 2024</a>, ranking&nbsp;7th.</p>
<p>‚≠ê I spent &gt;1,600 days working on a data science project that then failed because I lost interest. This article is to cope
with the failure and maybe help you (and me) to finish successful data science projects by summarising
a few learnings into a checklist, see <a class="reference external" href="#learnings">below</a>.</p>
<p>Nobody really likes to speak about failures. The same holds true for failed data science projects.
In this text, I document my most recent data science project which I worked on for 1,600 days -
days that I won&#8217;t get back despite the project failing.
Ultimately, it is important to communicate about failed projects similarly to successful projects
as those failed ones are the ones that help us to acquire scar tissue (<a class="reference external" href="https://youtu.be/I2ZK3ngNvvI?si=MkoLkVLl34ChHdW0&amp;t=111">thanks Andrej</a>) which makes us better data science
practitioners. And the latter is what we should all strive&nbsp;for!</p>
<div class="contents topic" id="table-of-contents">
<p class="topic-title"><a class="reference internal" href="#top">Table of&nbsp;Contents:</a></p>
<ul class="simple">
<li><a class="reference internal" href="#the-planned-project-its-failure" id="toc-entry-1">The planned project <span class="amp">&amp;</span> its&nbsp;failure</a></li>
<li><a class="reference internal" href="#data-source-tagesschau-newsticker" id="toc-entry-2">Data source: Tagesschau&nbsp;newsticker</a></li>
<li><a class="reference internal" href="#implementation-of-project-system-design" id="toc-entry-3">Implementation of project: System&nbsp;Design</a></li>
<li><a class="reference internal" href="#my-learnings-for-me-and-others" id="toc-entry-4">My learnings for me and&nbsp;others</a></li>
<li><a class="reference internal" href="#conclusion" id="toc-entry-5">Conclusion</a></li>
</ul>
</div>
<div class="section" id="the-planned-project-its-failure">
<h2><a class="toc-backref" href="#table-of-contents">The planned project <span class="amp">&amp;</span> its&nbsp;failure</a></h2>
<p>After completing <a class="reference external" href="https://lellep.xyz/blog/cycling-in-marburg-1-intro.html">a substantial hobby data analysis project</a> involving 1.5 million Nextbike
datapoints, I wanted to explore a different data modality: text. While my previous
work had focused on numerical analysis, I wanted to explore text as data source while delivering
some value. This opportunity presented itself in March 2020, just as <span class="caps">COVID</span>-19 began making
headlines. I discovered that Germany&#8217;s public news outlet, <a class="reference external" href="https://www.tagesschau.de/">Tagesschau</a>,
had launched a <span class="caps">COVID</span>-focused newsticker, aggregating everything from case numbers to policy changes
and breaking&nbsp;incidents.</p>
<p>The <span class="caps">COVID</span> newsticker provided both a compelling topic and an ideal text data
source. My plan was to scrape the entire newsticker over time and analyse it for both
metadata patterns, such as posting frequency, and deeper semantic insights about the people,
topics and countries involved. When <span class="caps">COVID</span> became less of an issue the Tagesschau shut down their
<span class="caps">COVID</span> newsticker in 2022-Q3 but launched a new one covering the emerging Ukraine-Russia war.
I seamlessly extended my project to collect also this new data&nbsp;stream.</p>
<p>I stopped working on the project in 2024-Q3 after 1,600 days of collecting data and some short data exploration
because life got busier, my priorities shifted and I had less free time at hand. Unfortunately, I never performed
any sort of serious data analyses except aforementioned short data exploration that I did after one week
into the project in&nbsp;2020-Q2.</p>
</div>
<div class="section" id="data-source-tagesschau-newsticker">
<h2><a class="toc-backref" href="#table-of-contents">Data source: Tagesschau&nbsp;newsticker</a></h2>
<p>The raw data format of the newsticker is shown in the figure below and explained in words below
the&nbsp;figure.</p>
<div class="figure">
<a class="reference external image-reference" href="https://lellep.xyz/blog/images/failed_data_science_project/2024-11-01_liveblog_data_format.jpg">
<img alt="" src="https://lellep.xyz/blog/images/failed_data_science_project/2024-11-01_liveblog_data_format.jpg" style="width: 900px;" />
</a>
<p class="caption">Raw format of newsticker data on Tagesschau website. Explanation see main&nbsp;text.</p>
</div>
<p>Every day featured a list of short news stories (shown in green),
each containing a timestamp, headline, body text and optional multimedia elements like Twitter/X
feeds, videos or audio clips. Each day normally linked back to the previous&nbsp;day.</p>
<p>I collected all the URLs and downloaded the underlying raw data from 2020-Q1 to 2024-Q3 for around
1,600 days while working towards my PhD and writing up my thesis. Then, I stopped because I lost
interest in the project and didn&#8217;t have time to continue it&nbsp;anymore.</p>
</div>
<div class="section" id="implementation-of-project-system-design">
<h2><a class="toc-backref" href="#table-of-contents">Implementation of project: System&nbsp;Design</a></h2>
<p>The system is a semi-automatic data pipeline which extracts raw data from the German news outlet Tagesschau
once a day and turns the raw unstructured data into structured news snippets that make up a dataset.
If I would have finished the project, this dataset would then have been released and used for
a number of analyses using&nbsp;Python.</p>
<p>The project system design is shown visually in the below figure and explained with words&nbsp;afterwards.</p>
<div class="figure">
<a class="reference external image-reference" href="https://lellep.xyz/blog/images/failed_data_science_project/2024-11-01_system_design.jpg">
<img alt="" src="https://lellep.xyz/blog/images/failed_data_science_project/2024-11-01_system_design.jpg" style="width: 400px;" />
</a>
<p class="caption">System design: Semi-automatic data pipeline for dataset curation that is used for&nbsp;analyses.</p>
</div>
<p>The data collection process involved a daily ritual of manually visiting the Tagesschau website to
capture links to both the <span class="caps">COVID</span> and later Ukraine war newstickers. While this manual approach constituted
the bulk of the project&#8217;s effort, it was necessitated by Tagesschau&#8217;s unstructured <span class="caps">URL</span> schema, which
made automated link collection&nbsp;impractical.</p>
<p>Every four to eight weeks, I would use Python to batch process these accumulated URLs, downloading the
underlying <span class="caps">HTML</span> pages as raw data. The emphasis on preserving raw <span class="caps">HTML</span> proved vital when Tagesschau
repeatedly altered their newsticker <span class="caps">DOM</span> structure throughout Q2 2020. This experience underscored a
fundamental data engineering principle: <strong>raw data is king</strong>. While parsers can be rewritten, lost data is&nbsp;irretrievable.</p>
<p>The technical pipeline itself was straightforward: Python scripts with BeautifulSoup4 parsed the
<span class="caps">HTML</span> pages into structured news items, which were then stored in an SQLite database. The end goal
was twofold: to share this unique dataset with the broader community and to conduct what I optimistically
labeled as &#8220;‚ù§Ô∏è Cool Analyses&#8221; - though these analyses would ultimately remain&nbsp;unrealized.</p>
<p>Many parts of the project were on autopilot. That is except for two parts: (1) the manual
<span class="caps">ETL</span> pipeline part and (2) the actual analyses. While part (2) would have been the actual fun part, I spent
1,600 days doing (1) starting in ~2020-03 and ultimately abandonning the project in&nbsp;2024-Q3.</p>
</div>
<div class="section" id="my-learnings-for-me-and-others">
<span id="learnings"></span><h2><a class="toc-backref" href="#table-of-contents">My learnings for me and&nbsp;others</a></h2>
<p>In the future, I will use the following short checklist of advice to conduct successful (data science) projects.
The list is roughly ordered by decreasing&nbsp;relevance:</p>
<ol class="arabic simple">
<li>Consider story telling from day one. While <a class="reference external" href="https://lellep.xyz/blog/cycling-in-marburg-1-intro.html">my Nextbike project</a>
had that built-in, this project would have been much more difficult to talk about because of the
negative topics of <span class="caps">COVID</span> and a&nbsp;war.</li>
<li>Get first analyses results out quickly based on a small dataset and don&#8217;t just collect data
up front to &#8220;analyse it later&#8221; - this is what I did here and it&#8217;s bad. Data postprocessing and
releasing some results as teasers are mostly important for you as after all, quick results keep
us motivated; e.g. for me, the present Tagesschau project was very interesting in the beginning
but I lost interest over time because of mindless data collecting. Ideally, given these first
results follow &#8220;<a class="reference external" href="https://austinkleon.com/show-your-work/">Show Your Work</a>&#8221; approach by making
the results public; this is super difficult for&nbsp;perfectionists.</li>
<li>Automate the h*ll out of your data science project (in particular the data acquisition part)
to reduce daily friction. If the automation process takes considerable work, then perceive it as a separate
topic to speak about online, again following the &#8220;<a class="reference external" href="https://austinkleon.com/show-your-work/">Show Your Work</a>&#8221; approach. For example,
the manual step in the process of my project could have been a beautiful and innovative machine
learning opportunity. Back then, I would have trained a specialised model (or used a pretrained specialised model)
but since LLMs made so much progress during the runtime of this project from 2020-Q1 to 2024-Q4, I would now
rather consider a foundational model wrapped as an <span class="caps">AI</span> agent instead; for example, I would try to find a
foundation model to do the job of for example finding the right link on the Tagesschau website, which was
by far the most draining part of the whole&nbsp;project.</li>
<li>Data cadence is relevant: Do you have to collect the data yourself over a period of time?
If yes, how often do you have to collect it - as in how often per hour for example? For the present
project, I had to scrape data only once per day, which is doable manually. For <a class="reference external" href="https://lellep.xyz/blog/cycling-in-marburg-1-intro.html">my previous NextBike project</a>,
however, I scraped data every 30 seconds. Since I scaped an <span class="caps">API</span>, the automation of that process was fairly&nbsp;simple.</li>
<li>Store raw data if possible. This allows you to condense it&nbsp;later.</li>
<li>Consider using the cloud for simplicity, reliability and last but certainly not least developing
real-life employability skills (<em>I am looking at you, University, that often fails to deliver the latter</em>).</li>
</ol>
</div>
<div class="section" id="conclusion">
<h2><a class="toc-backref" href="#table-of-contents">Conclusion</a></h2>
<p>Go out and build&nbsp;something!</p>
<p>A failed data science project is part of the learning experience and contributes
to your battle scar tissue; battle scar tissue through projects is a great concept from Andrej Karpathy
(see <a class="reference external" href="https://youtu.be/I2ZK3ngNvvI?si=MkoLkVLl34ChHdW0&amp;t=111">here</a> and <a class="reference external" href="https://stevengong.co/notes/Scar-Tissue">there</a>)
<span class="amp">&amp;</span> certainly makes us better data&nbsp;practitioners.</p>
<p>Personally, I would have loved to use the beautiful applied <span class="caps">ML</span> opportunity of identifying the right
newsticker link on the Tagesschau website using <span class="caps">NLP</span> to remove any manual labour but unfortunately, I don&#8217;t have
the time to do so. Also, I would have loved to evaluate the ~100,000 news
snippets that I collected and shared the dataset - but I will not; although I still think that these news analyses
would be super&nbsp;interesting!</p>
<p>Good news is that Tagesschau keeps releasing newstickers like for example for the <span class="caps">US</span> election 2024.
If you&#8217;re interested in picking up the project and getting some battle scars in, then please
drop me a message - I am happy to share the whole project with no strings attached&nbsp;:-).</p>
<hr class="docutils" />
<p>Thanks to everyone who proof-read early versions of this text:
<a class="reference external" href="https://www.linkedin.com/in/drsimonbarnes">Simon Barnes</a>.</p>
</div>

    </div>
  </article>

<!-- Mailchimp integration: Start -->

    <hr style="width: 100%; border-width: 2px; margin: auto; padding-bottom: 10px">

    <!-- Begin Mailchimp Signup Form -->
    <div id="mc_embed_signup" style="border-style: solid; padding: 10px; border-width: 2px; border-radius: 10px; border-color: rgba(0,0,0,.1); text-align: center">
    <form action="https://gmail.us1.list-manage.com/subscribe/post?u=57bbde295879632bd3d92ea44&amp;id=33caef11bd" method="post" id="mc-embedded-subscribe-form" name="mc-embedded-subscribe-form" class="validate" target="_blank" novalidate>
        <div id="mc_embed_signup_scroll">
            <i>Subscribe via email to get notified about new blog posts</i>
            <div class="mc-field-group">
                <input type="email" value="" name="EMAIL" class="required email" id="mce-EMAIL" placeholder="email address">
            </div>
            <div id="mce-responses" class="clear">
                <div class="response" id="mce-error-response" style="display:none"></div>
                <div class="response" id="mce-success-response" style="display:none"></div>
            </div>    <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->
            <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_57bbde295879632bd3d92ea44_33caef11bd" tabindex="-1" value=""></div>
            <div class="clear"><input type="submit" value="Subscribe" name="subscribe" id="mc-embedded-subscribe" class="button btn btn-light"></div>
        </div>
    </form>
    </div>
    <!--End mc_embed_signup-->

<!-- Mailchimp integration: End -->

    </div>
  </div>

  <footer class="footer">
    <div class="container">
<div class="row">
  <ul class="col-sm-6 list-inline">
    <li class="list-inline-item"><a href="https://lellep.xyz/blog/archives.html">Archives</a></li>
    <li class="list-inline-item"><a href="https://lellep.xyz/blog/categories.html">Categories</a></li>
      <li class="list-inline-item"><a href="https://lellep.xyz/blog/tags.html">Tags</a></li>
    <li class="list-inline-item">
        <a href="javascript:gaOptout()">Refuse analytics cookies</a>
    </li>
  </ul>
  <p class="col-sm-6 text-sm-right text-muted">
    Generated by <a href="https://github.com/getpelican/pelican" target="_blank">Pelican</a>
    / <a href="https://github.com/nairobilug/pelican-alchemy" target="_blank">&#x2728;</a>
  </p>
</div>    </div>
  </footer>

</body>

</html>